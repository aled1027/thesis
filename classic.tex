%!TEX root = thesis.tex
\chapter{Classic 2PC}
\al{this paragraph is a little weak}
Secure Computation was first proposed in an oral presesntation by Andrew Yao \cite{yao-original}.
Since Yao's presentation, two main methods have emerged for secure computation.
The first method is garbled circuits, and is the focus of this chapter.
The second method is GMW, and is explained in brief at the end of the chapter.

This chapter begins with motivating and describing desirable properties of a 2PC protocols, culminating in a defintion of security. 
Next, the chapter describes garbled circuits, a method popular method for performing 2PC.

\section{2PC Security Motivation}
Think back to Alice and Bob from the introduction. 
Alice and Bob are millionaires who wish to determine who is wealthier without disclosing how much wealth they have.
More formally, Alice has input $x$ and Bob has input $y$ ($x$ and $y$ are integers corresponding to the wealth of each party), and they wish to compute the less than function $f$, such that 
\begin{equation}
f(x,y) = \left\{
\begin{array}{lr}
    1 & \text{if } x < y \text{;} \\
    0 & \text{otherwise.}
\end{array}
\right.
\end{equation} 

We call the overarching interaction between Alice and Bob protocol $\Pi$, and $\Pi$ consists of all messages exchanged and computations performed.
Based on the setup of the problem, we can list a few properties that Alice and Bob wish $\Pi$ to have.
\begin{description}
    \item[Privacy] 
        Parties only learn their output. 
        Any information learned by a single party during the execution of $\Pi$ must be deduced from the output. 
        For example, if Alice learns that she had more money after computing $f$, then she learns that $y < x$; however, this information about $y$ is deducible from the output therefore it is reasonable.
        It would be unreasonable if Alice learns that $1,000,000 < y < 2,000,000$, as that information is not deducible from $f(x,y)$.
    \item[Correctness] 
        Each party receives the correct output.
        In the case of Alice and Bob, this simply means that they learn correctly who has more money.
        In particular, correctness means that Alice and Bob \textit{both} learn the output.

\end{description}

One possible method for constructing a definition of security would be to list a number of properties a secure protocol must have.
This approach is unsatisfactory for a number of reasons.

One reason is that an import security property that is only relevant in certain cases may be missed.
There are many applications of 2PC, and in some cases, there may be certain properties that critical to security.
Ideally, a good definition of 2PC works for all applications, hence capturing all desirable properties.
A second reason that the property based definition is unsatisfactory is that the definition should be simple.
If the definition is simple, then it should be clear that \textit{all} possible attacks against the protocol are prevented by the definition.
A definition based on properties in this respect as it becomes the burden of the prover of security to show that all relevant properties are covered \cite{lindell2009secure}.

We must also think about the aims of each party involved in the protocol. 
Can we trust that parties are going to obey the protocol? 
Are the parties going to try to cheat?
These considerations are called the \textit{security setting}.
There are two primary security settings: the semi-honest setting and the malicious setting. 

The work presented in this thesis uses the semi-honest setting. 
In the semi-honest setting, we assume that each party obeys the protocol but tries to learn as much as possible from the information they are given.
This means that parties do not lie about their information, they do not abort, they do not send or withhold messages out of order, or deviate in any way from what is specified in the protocol. 
In contrast, the malicious setting considers that each party is liable to lie and cheat; parties can take any action to learn more information.

The malicious setting is much more realistic. 
Parties that are involved in cryptographic protocols are liable to lie and cheat, for why else would they even be engaged in the cryptographic protocol in the first place?
There are two main reasons why the semi-honest setting is useful.
The first is that many protocols can be constructed for the semi-honest setting, and then improved to function in the malicious setting.
There is a strong history of this occurring with protocols.
It's simply easier to think through and create protocols for the semi-honest setting; at the very least, it's a valuable starting point for building complex cryptosystems.
In the case of 2PC, there exist malicious protocols, and in fact, the primary 2PC protocol that this thesis uses, garbled circuits, can be improved to be malicious secure without too much difficulty. 

The second reason that the semi-honest setting is that it does have use cases in the real world.
There are some scenarios where parties want to compute a function amongst themselves, and trust each other to act semi-honestly.
One example is hospitals sharing medical data.
Hospitals are legally, and arguably ethically, restricted from sharing medical data, but this data can have great value especially when aggregated with datasets from other hospitals.
2PC offers hospitals the means to ``share'' their data, perform statistics and other operations on it, while keeping the data entirely private. 
Other examples where semi-honesty is sufficient include mutually trusting companies and government agencies.

\section{2PC Security Definition}
% http://crypto.stackexchange.com/questions/3814/simulation-based-security
% page 620 of Goldreich volume 2
In this section we discuss at a high level the definition of 2PC security, and then give the formal definition. 
The definition of security for 2PC protocols is the most complicated cryptographic theory that we have encountered thus far. 

Recall our setup: Alice and Bob are semi-honest parties with inputs $x$ and $y$ respectively who wish to compute the function $f: \{0,1\}^n \times \{0,1\}^n \to \{0,1\}^m \times \{0,1\}^m$.
The protocol $\Pi$ is a 2-party computation protocol, that is instructions that Alice and Bob follow, that enables them to compute $f$.
To think about the security of $\Pi$, we imagine an ideal world where the protocol is computed securely, and compare the ideal world to the real world where $\Pi$ is executed.

In the ideal world, we imagine that there is a third, trusted and honest party Carlo.
Instead of Alice and Bob communicating amongst each other, Alice and Bob send their inputs to Carlo.
Carlo computes $f(x,y)$ himself, and sends the output to Alice and Bob.
The only information that Alice and Bob have in the ideal world is their individual inputs and the output.

Informally, we say that $\Pi$ is secure if Alice and Bob learn \textit{essentally the same} information executing $\Pi$ in the real world as they do computing $f$ in the ideal world with Carlo.
If either Alice or Bob manage to learn more information in the real world, then the protocol $\Pi$ is leaking information that cannot be deduced from their individual inputs and the output of $f$.
This idea of security is formally achieved using the concept of computational indistinguishability presented in Chapter 1. 
Recall that computational indistinguishability is the idea that two probability distributions are essentially the same - no polynomial time algorithm can distinguish them.
To use computational indistinguishability, we think of the information that Alice and Bob learn in the real and ideal world as probability distributions.
The idea may seem fuzzy now, but the idea will become clearer as the probability distrubtions are explained

To construct the probability distribution of the ideal world, we introduce \textit{simulators} $S_A$ and $S_B$.
$S_A$ and $S_B$ are probabilistic polynomial-time algorithms who are essentially adversaries, like the adversary in the definition of encryption from Chapter 1, that specifically attack the ideal world.
Simulator $S_A$ takes as input $x$, Alice's input, and $f(x,y)$, the output of the function because that is the information that Alice has access to in the ideal world.
Likewise, $S_B$ takes input $y$ and $f(x,y)$, since that the is information that Bob has access to in the ideal world.

To create a probability distribution, we consider what $S_A$ does over all possible input: the distribution of the possible outputs is given by $\{S_A(x, f(x,y)\}_{x \in \{0,1\}^*}$.
Let us break this distribution down: $S_A$ is a fixed single algorithm.
$x$ is Alice's input, and $f(x,y)$ is the output of the function.
The set is indexed by all possible $x$, so all possible inputs that Alice could have.
In summary, $\{S_A(x, f(x,y)\}_{x \in \{0,1\}^*}$ represents the possible information that an algorithm could deduced from all possible $x$ and $f(x,y)$.
We think of $\{S_B(y, f(x,y)\}_{y \in \{0,1\}^*}$ for Bob's input similarly.

In the real world, we need to consider what information Alice and Bob have at their disposal.
Recall that Alice and Bob are semi-honest, which means that Alice and Bob follow all instructions of $\Pi$, but they use any information they receive along the way.
More precisely, Alice and Bob obey the protocol, but also maintain a record of all messages sent and received.
We call Alice's record of communications Alice's \textit{view}, $\viewrv_A(x, y)$, which depends on inputs $x$ and $y$
And now we create the probability distribution for Alice: $\{\viewrv_A(x, y)\}_{x, y \in \{0,1\}^*}$.
This distribution represents the Alice's information from the exchanged messages indexed over all possible inputs $x$ and $y$.
Likewise, we call Bob's record of intermediate computations Bob's view,  $\viewrv_B(x, y)$, and his probability distribution of intermediate computations is $\{\viewrv_B(x, y)\}_{x,y \in \{0,1\}^*}\}$

To wrap it up, if $\Pi$ in the real world is the same as the Alice, Bob and Carlo in the ideal world, then the simulator $S_A$ and $S_B$ should only be able to learn what can be learned from the intermediate computations. 
That is, the probability distributions $\{S_A(x, f(x,y)\}_{x \in \{0,1\}^*}$ and $\{\viewrv_A(x, y)\}_{x, y \in \{0,1\}^*}\}$ should be essentially the same, i.e., computationally indstinguishable.

With this intuition in mind, we give Goldreich's definition of 2PC security from his textbook \textit{Foundations of Cryptography Volume II}\cite{goldreich}.

\begin{definition}
Let $f = (f_1, f_2)$ be a probabilistic, polynomial time functionality where Alice and Bob compute $f_1, f_2: \{0,1\}^n \to \{0,1\}^m$ respectively.
Let $\Pi$ be a two party protocol for computing $f$. 
Define $\viewrv_i^{\Pi}(n,x,y)$ (for $i \in \{1,2\}$) as the view of the $i$th party on input $(x,y)$ and security parameter $n$.
$\viewrv_i^{\Pi}(n,x,y)$ equals the tuple $(1^n, x, r^i, m_1^i, \ldots, m_t^i)$, where $r^i$ is the contents of the $i$th party's internal random tape, and $m_j^i$ is the $j$th message that the $i$th party received.
Define $output^{\Pi}_i(n,x,y)$ as the output of the $i$th party on input $(x,y)$ and security parameter $n$.
Also denote $ \outputrv^{\Pi}(n,x,y) = (\outputrv^{\Pi}_1(n,x,y), \outputrv^{\Pi}_2(n,x,y)).$
Note that $\viewrv^{\Pi}_i$ and $\outputrv^{\Pi}_i$ are random variables whose probabilities are taken over the random tapes of the two parties. Also note that for two party computation.

We say that $\Pi$ securely computes $f$ in the presence of static\footnote{\al{TODO} Mention what static means} semi-honest adversaries if there exist probabilistic polynomial time algorithms $S_1$ and $S_2$ such that for all $x,y \in \{0,1\}^*$, where $|x| = |y|$, the following hold:
\begin{equation} 
    \label{eqn:secdef1}
    \{(S_1(x, f_1(x,y), f(x,y)))\}_{x,y} \compindist \{(\viewrv^{\Pi}_1(x,y), \outputrv^{\Pi}(x,y)) \}_{x,y} 
\end{equation}
\begin{equation} 
    \label{eqn:secdef2}
    \{(S_2(x, f_2(x,y), f(x,y)))\}_{x,y} \compindist \{(\viewrv^{\Pi}_2(x,y), \outputrv^{\Pi}(x,y)) \}_{x,y} 
\end{equation}
\end{definition}

The definition requires that $|x| = |y|$; however, this constraint can be overcome by padding the shorter input.

A definition of 2PC security with malicious parties is substantially more complex.
For more information on a malicious security definition, we refer the reader to \cite{lindell2009}.

\section{Yao's Garbled Circuit}
We now discuss a popular 2PC scheme called garbled circuits.
At a high level, garbled circuits work by having one party, Alice, design a circuit that computes $f$.
Alice encrypts (garble) that circuit and sends the encrypted circuit to Bob, along with some values corresponding to her and Bob's inputs.
Bob decrypts the circuit, acquring the output of $f(x,y)$ at the end.

\begin{figure}
\label{fig:gc-highlevel}
\centering
%\footnotesize
\scriptsize
\begin{center}
\fbox{
\begin{protocol}{2}
%\protocolheader{High Level Garbled Circuit}
\participants{Alice}{Bob}\\
\text{Input $x$} & & \text{Input $y$}\\
\C \gets {\sf CreateCircuit}(f) \\
\GC, \InputLabels \gets {\sf GarbleCircuit(C)} \\
\InputLabels_x, \InputLabels_y \gets \InputLabels \\
& \sends{\GC} \\
& \sends{\InputLabels_x} \\
& \sends{\InputLabels_y \text{ via OT}} \\
& & {\sf Evaluate(\GC, \InputLabels_x, \InputLabels_y)} \\
%& \exchange{\OT(\AllInputLabels, $y$)} & \InputLabels \\
%& \sends{\InputLabels} & \InputLabels \\
% %& \receives{z} \\
\end{protocol}}
\end{center}
\caption{A high level overview of the garbled circuit protocol \al{ask cat - text too small?}}
\end{figure}




\begin{figure}[h]
    \center
    \label{fig:thefig}
\centering

\begin{circuitikz} \draw
% http://tex.stackexchange.com/questions/55213/how-to-draw-a-boolean-circuit-diagram-in-circuitikz
% http://texdoc.net/texmf-dist/doc/latex/circuitikz/circuitikzmanual.pdf
% adapted from figure on page 40
(0,2) node[and port] (myand1) {}
(0,0) node[and port] (myand2) {}
(3,1) node[xor port] (myxor) {}
(myand1.in 1) node[left=.8cm](a) {$x_0$}
(myand1.in 2) node[left=.8cm](b) {$x_1$}
(myand2.in 1) node[left=.8cm](c) {$y_0$}
(myand2.in 2) node[left=.8cm](d) {$y_1$}
(myxor.out) node[right=.5cm](e) {$z_0$}
(myxor.out) node[right=.25cm](f) {}
(a) -| (myand1.in 1)
(b) -| (myand1.in 2)
(c) -| (myand2.in 1)
(d) -| (myand2.in 2)
(myand1.out) -| (myxor.in 1)
(myand2.out) -| (myxor.in 2)
(myxor.out) -| (f);
\node at (-.7,2.0) {$G_0$};
\node at (-.7,0.0) {$G_1$};
\node at (2.4,1.0) {$G_2$};

\node at (-1.7,2.5) {$W_0$};
\node at (-1.7,2.0) {$W_1$};
\node at (-1.7,0.5) {$W_2$};
\node at (-1.7,0.0) {$W_3$};
\node at (0.7,2.3) {$W_4$};
\node at (0.7,0.3) {$W_5$};

\node at (3.35,1.25) {$W_5$};


\end{circuitikz}
\caption{A simple boolean circuit. \al{Draw gate and wire number notation in here}}
\end{figure}

\al{figure numbering is off}
We now walk through how Alice garbles a circuit.
She starts with a typical boolean circuit, like the one shown in figure \ref{fig:thefig}.
In figure \ref{fig:thefig} the gates are ordered from $0$ to $2$, in order from nearest to the inputs to farthest from the inputs.
Alice begins by assigning two wire labels to each wire - a wire is a line connecting the inputs and gates in the figure.
Because Alice is working with a boolean circuit, each wire can be represented by either a 0 or 1.
For a given wire $W_i$, the zeroith wire label $W_i^0$ represents $0$, and the first wire label $W_i^1$ represents $1$.
We use $W_i$ to represent the $i$th wire, $W_i^j$ to represent the $i$ wire's $j$ label, and later we use $W_i^*$ to represent one of wire $i$'s wire labels (without being specific about whether it is wire label 0 or wire label 1).
A wire labels is a ciphertext, the output of the encryption algorithm\footnote{A common encryption algorithm used now is AES-128, so the wire labels are 128 bit strings.}.
Alice assigns the wire labels by randomly sampling from $\{0,1\}^{\lambda}$, where $\lambda$ is the size of the output of the encryption algorithm.

After assigning wire labels, Alice first garbles gate $G_0$, the gate nearest to the inputs\footnote{Multiple gates at some point could equidistant from the input. In these cases, the ordering of gates does not matter.}.
Alice garbles by creating a garbled table $T_{G_0}$ for $G_0$.
Gate $G_0$ is an AND gate, so the structure of the table resembles the logical table for an AND gate.
The table has four columns. 
The first two columns are the input wire labels; in this case, these are wires $W_0$ and $W_1$.
The third column is the wire labels for the output wire; this case $W_5$
The wire label placed in the third column is based on logical operation of the AND gate.
For example, the third column and third row has the wire label associated with $0$, since AND outputs zero on input of $0$ and $1$.
The fourth column is the dual-key cipher encryption\footnote{See section \al{what section?} for information on dual-key ciphers} of the value in the third column, using the values of the first two columns as keys.
The garbled table for $G_0$ is shown in table \ref{tbl:g0-table}

\begin{table}[h]
\centering
\label{tbl:g0-table}
\begin{tabular}{|c|c|c|c|}
\hline
$W_0$ & $W_1$ & $W_5$ & Encryption \\
\hline
$W_0^0$ & $W_1^0$ & $W_5^0$ & $\Enc_{W_0^0, W_1^0}(W_5^0)$ \\
$W_0^1$ & $W_1^0$ & $W_5^0$ & $\Enc_{W_0^1, W_1^0}(W_5^0)$ \\
$W_0^0$ & $W_1^1$ & $W_5^0$ & $\Enc_{W_0^0, W_1^1}(W_5^0)$ \\
$W_0^1$ & $W_1^1$ & $W_5^1$ & $\Enc_{W_0^1, W_1^1}(W_5^1)$ \\
\hline
\end{tabular}
\caption{A garbled table for an AND gate with input wires $W_0$ and $W_1$ and output wire $W_5$.}
\end{table}

Alice creates garbled tables all remaining gates; in this case, $G_1$ and $G_2$ remain.
She then sends the fourth column all of garbled tables, the encryption of the respective out-wires, to Bob.
Now if Bob has a label for each input wire, then Bob can acquire one of the labels of the output wire.
More formally, say a gate was input wires $W_i$ and $W_j$ and output wire $W_k$.
Bob can acquire a wire label of $W_k$ (i.e. $W_k^0$ or $W_k^1$) if he has one wire label of $W_i$ (i.e. $W_i^0$ or $W_i^1$) and one wire label of $W_j$ (i.e. $W_j^0$ or $W_j^1$).

In order to decrypt each gate, Bob needs to first acquire the wire lables of the input wires, $W_0$, $W_1$, $W_2$ and $W_3$.
Recall that Alice's input to the 2PC protocol are $x = x_0x_1$ where $x_1, x_0 \in \{0,1\}$.
Alice communicates her input to Bob, without revealing values of $x_i$, by sending wire labels $W_0^{x_0}$ and $W_1^{x_1}$.
Bob does not know the values of $x_0$ or $x_1$, because he is simply receiving two ciphertexts, and does not know which value the ciphertexts represent.
The only information that Bob has is the fourth column of the garbled tables, and that does not provide any information about the sematic value of the wire labels.

Recall that Bob's input to the 2PC protocol is $y = y_0 y_1$ where $y_1, y_0 \in \{0,1\}$.
Alice now wants to send Bob $W_2^{y_0}$ and $W_3^{y_1}$, but she does not know and cannot know (for the sake of security) $y_0$ and $y_1$.
Alice and Bob can achieve this by using Oblivious Transfer, as described in Chapter 1.
As an example, we look at wire $W_2$.
Alice has two possible values that she wants to send to Bob: $W_2^0$ and $W_2^1$.
Alice only wants Bob to acquire one of the values, becuase otherwise he can decrypt multiple rows garbled table.
\al{introduce htis OT notation in Chapter 1}
Bob wants to receive $W_2^{y_0}$, as that wire label corresponds to his input.
So Alice and Bob do $\OT(\{W_2^0, W_2^1\}, y_0)$, so that Alice obvliously sends Bob the correct wire label.
Alice and Bob also perform OT on wire $W_3$; in particular, they do $\OT(\{W_3^0, W_3^1\}, y_1)$.

Alice is finished garbling the circuit, and communicating information to Bob. 
Bob has everything he needs to ungarble, or decrypt, the circuit.
Bob starts with gate $G_0$, for which he has the fourth column of $T_{G_0}$, a wire label for wire $0$, which I denote $W_0^*$ since Bob does not which wire label it is, and $W_1^*$ accordingly.
Bob starts with the first row of $T_{G_0}$ and tries decrypting the value using $W_0^*$ and $W_1^*$.
Formally, Bob tries $\EncInv_{W_0^*, W_1^*}(T_{G_0}\big[0\big])$ where $T_{G_0}\big[0\big]$ represents the value in the zeroith row of $T_{G_0}$.
Bob tries decrypting the values in all four rows of the garbled table $T_{G_0}$, but only one should work, since the other decryptions using the incorrect keys.
For Bob to recognize that encryption is failing, we add an additional property to the encryption scheme: the output of the decryption function should indicate whether the decryption was valid.
A single additional bit, where $0$ represents that decryption failed and $1$ represents that decryption was successful. 
It is noteworth that such a property is common to encrypion schemes, and can be added to any existing encryption if necessary.
With this property, as Bob tries decrtyping all four rows of the garbled table, only one should decrypt correctly.
Because of the way Alice constructed the garbled table, Bob knows that this correclty decrypted value is one of the wire labels of $W_5$, the output wire of gate $G_0$.
Bob then assigns this decrypted value to $W_5^*$, and uses the value as the input wire when decrypting gate $G_2$.

Bob repeats this same process for gate $G_1$ and for gate $G_2$.
For gate $G_2$, Bob uses wire labels $W_5^*$ and $W_6^*$ which he acquired by ungarbling gates $G_0$ and $G_1$.
Bob notifes Alice after acquiring $W_7^*$.
Alice sends him values $W_7^0$ and $W_7^1$.
If $W_7^* = W_7^0$, then the function output $0$ and Bob notifes Alice that the output was $0$.
Otherwise if $W_7^* = W_7^0$, then the function output $1$ and Bob notifes Alice that the output was $1$.

Bob and Alice have now securely computed the function.

\al{Match notation in this description with the algorithms}

\begin{algorithm}
\caption{Garble Circuit}
\label{alg:garble}
\begin{algorithmic}
    \Require Circuit $f(x,\cdot)$ 
    \Ensure Populate garbled tables $f(x,\cdot).tables$.
\For{wire $w_i$ in $f(x,\cdot).wires$} 
    \State Generate two encryption keys, called garbled values, $W_i^0$ and $W_i^1$.
    \State Assign $(W_i^0, W_i^1)$ to $w_i$.
\EndFor \\

\For{gate $g$ in $f(x,\cdot).gates$}
    \State Let $w_i$ be $g$'s first input wire.
    \State Let $w_j$ be $g$'s second input wire.
    \State Let $w_k$ be $g$'s output wire.
    \For{$(u,v) \in \{(0,0), (0,1), (1,0), (1,1)\}$}
    \State $T_g[u,v] = \Enc_{W_i^u}( \Enc_{W_j^v} ( W_k^{g(u,v)}))$
    \al{use DKC}
    \EndFor
    \State $f(x,\cdot).tables[g] = T_g$.
\EndFor
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Evaluate Circuit}
\label{alg:evaluate}
\begin{algorithmic}

\Require $(input\_wires, tables, gates)$
\For{Input wire $w_i$ in $input\_wires$}
	\Comment retrieve garbled values of input wires
	\State Perform OT$(w_i, x_i)$ 
	\Comment retrieve $W^{x_i}_i$ from Alice
	\State Save the value to $w_i$.
\EndFor

\For{Gate $g$ in $gates$}
	\Comment compute the output of each gate.
	\State Let $w_i$ be $g$'s first input wire.
	\State Let $w_j$ be $g$'s second input wire.
	\State Let $w_k$ be $g$'s output wire.
	\State \textbf{Require} $w_i$ and $w_j$ have been assigned garbled values.
	\State \textbf{Require} $w_k$ has not been assigned a garbled value.
    	\For{$(u,v) \in \{(0,0), (0,1), (1,0), (1,1)\}$}
        \al{use DKC}
		\State $temp = \Dec_{w_j}(\Dec_{w_i}(tables[g][u,v]))$
		\If{$temp$ decrypted correctly}
			\State $w_k = temp$
		\EndIf
	\EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

\subsection{Security of Garbled Circuits}
We now discuss the security of garbled circuits without proof.

The definition of security of a 2PC protocol $\Pi$ given early in Chapter 2 asked us to compare the execution of $\Pi$ in the real world to an ideal 2PC execution with a trusted third party Carlo.
This definition is extremely useful; however, it is difficult to adapt it to intuiting the security of a given protocol.
To think about the security of garbled circuits, we think about the information that Alice and Bob.

The only information that Alice receives from Bob during the execution of garbled circuits is in the OT stage.
Thereby the security on Alice's side is dependent on the security of OT, whose security we describe in Chapter 1.
Hence, we can confidently say that Alice does not learn anything during garbled circuits.

The security of Bob is more complicated.
Bob learns three sets of information: a single wire label for each wire (i.e. input labels)  and the fourth column of the garbled table for each gate.
The input labels are acquired in two ways: some are sent naiively by Alice and some are acquired via OT.
We can be confident that Bob doesn't learn any extra informatin in the process of receiving the labels, since we are confident that OT does not reveal information, and other labels are coldly sent by Alice.
Moreover, knowing input labels associated with Alice's input doesn't give Bob any information, since he cannot tell if the label is associated with 0 or 1.

The fourth column of the garbled table by itself does not reveal any information to Bob, as it is simply the encryption of things.
Bob has the keys to decrypt some of the values in the garbled table.
We need to be sure that Bob only has the keys to decrypt the single, intended row of the table.
Bob can only decrypt a row of the table if he has both of the labels used as keys.
For gates on that are connected to input wires, Bob only has a single label for each wire, therefore he must only be able to decrypt a single row.
For subsequent gates, Bob will only ever have a single label for each wire, meaning he can only decrypt a single row.

For Bob to learn extra information, he needs to acquire two wire labels for a single wire.
If he can acquire two labels, then he can decrypt the circuit using that wire label, and with some thinking learn about Alice's input.
Based on the information that Bob has, there is no way he can access two wire labels for a single wire.
And that is the intuition behind the security of garbled circuits.
Of course without a formal proof using computational indistinguishability, we cannot be confident that garbled circuits are secure, as there may be an attack that eludes us.

\subsection{Notes about complexity}
There are three things to think about when considering the complexity of garbled circuits.
The first is the amount of information that needs to be communicated per gate.
Garbled circuits require 4 ciphertexts, that is $4\lambda$ bits.
On top of this communication is Alice sending her input labels, and the communication required to complete OT for Bob's input labels.
OT, if used naively, is a significant contributor to overall bandwidth.

The second thing to consider is the amount of computation that Alice performs.
Alice performs 4 encryptions with a dual-key cipher for each gate.

The third cost to consider is the amount of computation that Bob performs.
Bob performs 4 decrypts with the dual-key cipher for each gate.

These constraints are all important, but in practice the biggest bottlenecks are the communication per gate and Bob's computation, which are correlated as we see in Chapter 3.
A circuit that computes AES requires approximately 35,000 gates.
If 4 ciphertexts per gate need to communicated, and AES-128 is the encryption scheme, then $4 * 128 * 35,000$ bits = $2.24$ megabytes: a huge amount of communication for just encryption!

\section{GMW}
Where Yao's protocol is premised on encrypting gates individually, GMW's protocol for garbling circuits is premised on secret sharing and performing operations on the shared secrets. 
In general, secret sharing is a class of methods for distributing a secret to a group of participants, where each participants is allocated a \textit{share} of the secret. 
The secret can only be reconstructed when a sufficient number of the participants combine their shares, but any pool of insufficient shares yields no information about the secret.

GMW begins by having Alice and Bob secret share their inputs, so each party now has a collection of \textit{shares}. 
Algorithm \ref{alg:gmw_setup} describes this process in more detail.
Then Alice and Bob perform a series of operations on their shares, which are dictated by the gates in the function they wish to compute.
As with Yao's protocol, a gate may either compute XOR, AND or NOT.
Each operation requires a different series of operations, which are described in Algorithm \ref{alg:gmw_gates}.
Finally, Alice and Bob publicize their shares to each other, at which point each party will have sufficient shares to compute the output of the function.

%\begin{algorithm}[h!]
%\caption{GMW Setup}
%\label{alg:gmw_setup}
%\begin{algorithmic}
%% http://crypto.biu.ac.il/gmw-multi-party-protocol-and-oblivious-transfer-extension
%    \State Alice does the following on input Circuit $f(x,\cdot)$ and $x = x_0x_1\ldots x_n$
%    \For{wire $w_i$ in $f(x, \cdot).wires$}
%        \State Assign $a^1_{w_i} \leftarrow \{0,1\}$
%        \Comment a uniform random selection of $0$ or $1$.
%        \State Assign $b^1_{w_i} = x_i \oplus a_{w_i}^1$
%    \EndFor
%    \State Bob does likewise on input Circuit $f(x,\cdot)$ and $y = y_0y_1\ldots y_n$
%    \State Hence Alice has generated shares $\{a^1_w, b^1_w\}_w$ 
%    \State and Bob has generated shares $\{a^2_w, b^2_w\}_w$
%    \State Alice and Bob divide the shares such that Alice has all $a_w$ and Bob has all $b_w$.
%\end{algorithmic}
%\end{algorithm}
%
%\begin{algorithm}
%\caption{GMW Gate Evaluation}
%\label{alg:gmw_gates}
%\begin{algorithmic}
%    \State \textbf{XOR Gate}
%    \Comment $x_i \oplus y_i = (a_{w_i}^1 \oplus b_{w_i}^1) \oplus (a_{w_i}^2 \oplus a_{w_i}^2)$
%    \State Alice evaluates $a_{w_i}^1 \oplus a_{w_i}^2$
%    \State Bob evaluates $b_{w_i}^1 \oplus b_{w_i}^2$
%    \\
%    
%    \State \textbf{AND Gate}
%    \Comment $x_i \wedge y_i = (a_{w_i}^1 \oplus b_{w_i}^1) \wedge (a_{w_i}^2 \oplus a_{w_i}^2)$
%    \State Alice samples $\sigma \leftarrow \{0,1\}$
%    \Comment a uniform random selection of $0$ or $1$
%    \State Alice constructs table $T$:
%     \For{$(u,v) \in \{(0,0), (0,1), (1,0), (1,1)\}$}
%     	\State $T[u,v] = (a^1_{w_i} \oplus u) \wedge (a^2_{w_i} \oplus v)$
%	\State $s[u,v] = \sigma \oplus T[u,v]$.
%     \EndFor    
%     \State Do 1-4OT. Alice sends $(s[0,0], s[0,1], s[1,0], s[1,1])$ 
%     \State Bob selects result based on $(u,v) = (b^1_{w_i}, b^2_{w_i})$.
%    \\
%    
%    \State \textbf{NOT Gate}
%    \Comment $w_i = (\neg a_{w_i}) \oplus (\neg b_{w_i})$
%    \State $\triangleright$ Evaluate the negative of a particular wire $w_i$. 
%    \State $w_i = a_{w_i} \oplus b_{w_i}$
%    \State Let $a'_{w_i} = 1 \oplus a_{w_i}$
%    \Comment i.e. $a'_{w_i} = \neg a_{w_i}$
%    \State Let $b'_{w_i} = 1 \oplus b_{w_i}$
%    \Comment i.e. $b'_{w_i} = \neg b_{w_i}$
%\end{algorithmic}
%\end{algorithm}
%
%\al{see mike rosulek first few slides for good images. }
%\al{illustration about translating bits over to wire labels}
