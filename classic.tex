%!TEX root = thesis.tex
\chapter{Classic 2PC}
\al{this paragraph is a little weak}
Secure Computation (SC) was first proposed in an oral presesntation by Andrew Yao \cite{yao-original}.
Since Yao's presentation, multiple methods for performing SC were developed.
One method was developed by Yao himself and is called garbled circuit.
Another was developed by a group of researchers, Goldreich, Micali and Widgerson \al{cite}.
The two methods are premised on a similar idea: encrypt a circuit by encrypting its gates, which has since been termed garbled circuit.
At this point, it is unclear which method is better, so researchers continue to study both methods.
\al{get source}

This chapter explains the two most prominent methods of SC for the two party case, referred to as Two-Party Protocol (2PC).
The first part of the chapter will motivate and describe desirable properties of a 2PC protocol, culminating in a definition. 
The second part of the chapter will describe in Yao's Garbled Circuits, a method for performing 2PC, and discuss security of 2PC.
The third part will provide an overview of GMW's method.

\section{2PC Security Motivation}
Think back to Alice and Bob from the introduction. 
Alice and Bob are millionaires who wish to determine who is wealthier without disclosing how much wealth they have.
More formally, Alice has input $x$ and Bob has input $y$ ($x$ and $y$ are integers corresponding to the wealth of each party), and they wish to compute the less than function $f$, such that 
\begin{equation}
f(x,y) = \left\{
\begin{array}{lr}
    1 & \text{if } x < y \text{;} \\
    0 & \text{otherwise.}
\end{array}
\right.
\end{equation} 

We call the overarching interaction between Alice and Bob protocol $\Pi$, and $\Pi$ consists of all messages exchanged and computations performed.
Based on the setup of the problem, we can list a few properties that Alice and Bob wish $\Pi$ to have.
\begin{description}
    \item[Privacy] 
        Parties only learn their output. 
        Any information learned by a single party during the execution of $\Pi$ must be deduced from the output. 
        For example, if Alice learns that she had more money after computing $f$, then she learns that $y < x$; however, this information about $y$ is deducible from the output therefore it is reasonable.
        It would be unreasonable if Alice learns that $1,000,000 < y < 2,000,000$, as that information is not deducible from $f(x,y)$.
    \item[Correctness] 
        Each party receives the correct output.
        In the case of Alice and Bob, this simply means that they learn correctly who has more money.
        In particular, correctness means that Alice and Bob \textit{both} learn the output.

\end{description}

One possible method for constructing a definition of security would be to list a number of properties a secure protocol must have.
This approach is unsatisfactory for a number of reasons.

One reason is that an import security property that is only relevant in certain cases may be missed.
There are many applications of 2PC, and in some cases, there may be certain properties that critical to security.
Ideally, a good definition of 2PC works for all applications, hence capturing all desirable properties.
A second reason that the property based definition is unsatisfactory is that the definition should be simple.
If the definition is simple, then it should be clear that \textit{all} possible attacks against the protocol are prevented by the definition.
A definition based on properties in this respect as it becomes the burden of the prover of security to show that all relevant properties are covered \cite{lindell2009secure}.

We must also think about the aims of each party involved in the protocol. 
Can we trust that parties are going to obey the protocol? 
It's relevant in the two party case, but if there are more than three parties, parties may either act independently or collude. 
These considerations are called the \textit{security setting}.
There are two primary security settings: the semi-honest setting and the malicious setting. 
The work presented in this thesis uses the semi-honest setting. 
In the semi-honest setting, we assume that each party obeys the protocol but tries to learn as much as possible from the information they are given.
This means that parties do not lie about their information, they do not abort, they do not send or withhold messages out of order, or deviate in any way from what is specified in the protocol. 
In contrast, the malicious setting considers that each party is liable to lie and cheat; parties can take any action to learn more information.

The malicious setting is much more realistic. 
Parties that are involved in cryptographic protocols are liable to lie and cheat, for why else would they even be engaged in the cryptographic protocol in the first place?
There are two main reasons why the semi-honest setting is useful.
The first is that many protocols can be constructed for the semi-honest setting, and then improved to function in the malicious setting.
There is a strong history of this occurring with protocols.
It's simply easier to think through and create protocols for the semi-honest setting; at the very least, it's a valuable starting point for building complex cryptosystems.
In the case of 2PC, there exist malicious protocols, and in fact, the primary 2PC protocol that this thesis uses, garbled circuits, can be improved to be malicious secure without too much difficulty. 

The second reason that the semi-honest setting is that it does have use cases in the real world.
There are some scenarios where parties want to compute a function amongst themselves, and trust each other to act semi-honestly.
One example is hospitals sharing medical data.
Hospitals are legally, and arguably ethically, restricted from sharing medical data, but this data can have great value especially when aggregated with datasets from other hospitals.
2PC offers hospitals the means to ``share'' their data, perform statistics and other operations on it, while keeping the data entirely private. 
Other examples where semi-honesty is sufficient include mutually trusting companies and government agencies.

\section{2PC Security Definition}
% http://crypto.stackexchange.com/questions/3814/simulation-based-security
% page 620 of Goldreich volume 2
In this section we discuss at a high level the definition of 2PC security, and then give the formal definition. 
The definition of security for 2PC protocols is the most complicated cryptographic theory that we have encountered thus far. 

Recall our setup: Alice and Bob are semi-honest parties with inputs $x$ and $y$ respectively who wish to compute the function $f: \{0,1\}^n \times \{0,1\}^n \to \{0,1\}^m \times \{0,1\}^m$.
Informally, we say $\Pi$ is scure if when $\Pi$ is executed in the real world, each party learns the same information as if they had completed the protocol in an ideal world.
The ideal world is where there is a trustred third party Carlo who receives the inputs $x$ from Alice and $y$ from Bob, computes the $f(x,y)$, and sends the output to Alice and Bob.
Carlo is honest and trusted, so we don't mind that he knows the inputs, and he is trusted to not share the inputs with the opposoring party.
This is the ideal world: the function is compute correctly, and no information about the inputs is shared to other parties.

In the real world, Alice and Bob do not have luxury of enlisting Carlo to perform their computation for them; instead, they use the 2PC protocol $\Pi$. 
To be confident that $\Pi$ is secure, we show that $\Pi$ in the real world is \textit{essentially the same} as Alice, Bob and Carlo acting in the ideal world.
Specifically, Alice and Bob should not learn any more information in the real world than they do in the ideal world.
If they do learn more information, then somewhere the protocol $\Pi$ is leaking information that cannot be deduced from the output of $f$. 
We show that the ideal is world is essentially the same as the ideal world by using the concept of computational indistinguishability presented in chapter 1.
To use computational indistinguishability, we need to build probability distrubtions of the information deducible in the real and ideal world.
Next, we construct probability distributions of the information that Alice and Bob can deduce from the ideal and real world.

To construct the probability distribution of the ideal world, we introduce \textit{simulators} $S_A$ and $S_B$.
$S_A$ and $S_B$ are probabilistic polynomial-time algorithms who are essentially adversaries, like the adversary in the definition of encryption from chapter 1, that specifically attack the ideal world.
Simulator $S_A$ takes as input $x$, Alice's input, and $f(x,y)$, the output of the function because that is the information that Alice has access to in the ideal world.
Likewise, $S_B$ takes input $y$ and $f(x,y)$, since that the is information that Bob has access to in the ideal world.

Given a simulator $S_A$, think about what the simulator can do.
The distribution of the its possible outputs is given by $\{S_A(x, f(x,y)\}_{x \in \{0,1\}^*}$.
Let us break this distribution down: $S_A$ is a fixed single algorithm.
$x$ is Alice's input, and $f(x,y)$ is the output of the function.
The set is indexed by all possible $x$, so all possible inputs that Alice could have.
In summary, $\{S_A(x, f(x,y)\}_{x \in \{0,1\}^*}$ represents the possible information that an algorithm could deduced from all possible $x$ and $f(x,y)$.
We think of $\{S_B(y, f(x,y)\}_{y \in \{0,1\}^*}$ for Bob's input similarly.

For constructing the probability distributions of the real world, we need to consider what information Alice and Bob have at their disposal.
Recall that Alice and Bob are semi-honest, which means that Alice and Bob follow all instruction of $\Pi$ correctly but they also will use any information they receive along the way.
More precisely, Alice and Bob obey the protocol, but also maintain a record of all intermediate computations.
We call Alice's record of intermediate computations Alice's \textit{view}, $\viewrv_A(x, y)$, which depends on inputs $x$ and $y$
And now we create the probability distribution for Alice: $\{\viewrv_A(x, y)\}_{x, y \in \{0,1\}^*}\}$.
This distribution represents the Alice's information from the intermediate computation indexed over all possible inputs $x$ and $y$.
Likewise, we call Bob's record of intermediate computations Bob's view,  $\viewrv_B(x, y)$, and his probability distribution of intermediate computations is $\{\viewrv_B(x, y)\}_{x,y \in \{0,1\}^*}\}$

To wrap it up, if $\Pi$ in the real world is the same as the Alice, Bob and Carlo in the ideal world, then the simulator $S_A$ and $S_B$ should only be able to learn what can be learned from the intermediate computations. 
That is, the probability distributions $\{S_A(x, f(x,y)\}_{x \in \{0,1\}^*}$ and $\{\viewrv_A(x, y)\}_{x, y \in \{0,1\}^*}\}$ should be essentially the same, i.e., computationally indstinguishable.

With this intuition in mind, we give Goldreich's definition of 2PC security from his textbook \textit{Foundations of Cryptography Volume II}\cite{goldreich}.

\begin{definition}
Let $f = (f_1, f_2)$ be a probabilistic, polynomial time functionality where Alice and Bob compute $f_1, f_2: \{0,1\}^n \to \{0,1\}^m$ respectively.
Let $\Pi$ be a two party protocol for computing $f$. 
Define $\viewrv_i^{\Pi}(n,x,y)$ (for $i \in \{1,2\}$) as the view of the $i$th party on input $(x,y)$ and security parameter $n$.
$\viewrv_i^{\Pi}(n,x,y)$ equals the tuple $(1^n, x, r^i, m_1^i, \ldots, m_t^i)$, where $r^i$ is the contents of the $i$th party's internal random tape, and $m_j^i$ is the $j$th message that the $i$th party received.
Define $output^{\Pi}_i(n,x,y)$ as the output of the $i$th party on input $(x,y)$ and security parameter $n$.
Also denote $ \outputrv^{\Pi}(n,x,y) = (\outputrv^{\Pi}_1(n,x,y), \outputrv^{\Pi}_2(n,x,y)).$
Note that $\viewrv^{\Pi}_i$ and $\outputrv^{\Pi}_i$ are random variables whose probabilities are taken over the random tapes of the two parties. Also note that for two party computation.

We say that $\Pi$ securely computes $f$ in the presence of static\footnote{\al{TODO} Mention what static means} semi-honest adversaries if there exist probabilistic polynomial time algorithms $S_1$ and $S_2$ such that for all $x,y \in \{0,1\}^*$, where $|x| = |y|$, the following hold:
\begin{equation} 
    \label{eqn:secdef1}
    \{(S_1(x, f_1(x,y), f(x,y)))\}_{x,y} \equiv^C \{(\viewrv^{\Pi}_1(x,y), \outputrv^{\Pi}(x,y)) \}_{x,y} 
\end{equation}
\begin{equation} 
    \label{eqn:secdef2}
    \{(S_2(x, f_2(x,y), f(x,y)))\}_{x,y} \equiv^C \{(\viewrv^{\Pi}_2(x,y), \outputrv^{\Pi}(x,y)) \}_{x,y} 
\end{equation}
\end{definition}

The definition requires that $|x| = |y|$; however, this constraint can be overcome by padding the shorter input.

A definition of 2PC security with malicious parties is substantially more complex.
For more information on a malicious security definition, we refer the reader to \cite{lindell2009}.

\section{Yao's Garbled Circuit}
We now discuss a popular 2PC scheme called garbled circuits.
At a high level, garbled circuits work by having one party, Alice, design a circuit that computes $f$ and encrypt (garble) that circuit.
Alice sends the encrypted circuit to Bob, along with some values corresponding to her and Bob's inputs, and Bob decrypts the circuit, acquring the output of $f(x,y)$ at the end.

\begin{figure}[h]
    \label{fig:thefig}
\centering
\begin{circuitikz} \draw
(0,2) node[and port] (myand1) {}
(0,0) node[and port] (myand2) {}
(3,1) node[xor port] (myxor) {}
(myand1.in 1) node[left=.8cm](a) {$x_0$}
(myand1.in 2) node[left=.8cm](b) {$x_1$}
(myand2.in 1) node[left=.8cm](c) {$y_0$}
(myand2.in 2) node[left=.8cm](d) {$y_1$}
(myxor.out) node[right=.5cm](e) {$z_0$}
(myxor.out) node[right=.25cm](f) {}
(a) -| (myand1.in 1)
(b) -| (myand1.in 2)
(c) -| (myand2.in 1)
(d) -| (myand2.in 2)
(myand1.out) -| (myxor.in 1)
(myand2.out) -| (myxor.in 2)
(myxor.out) -| (f)
;\end{circuitikz}
\caption{A simple boolean circuit. \al{Draw gate and wire number notation in here}}
\end{figure}

\al{figure numbering is off}
We now walk through how Alice garbles the circuit.
She starts with a typical boolean circuit, like the one shown in figure \ref{fig:thefig} \al{add figure of basic circuit with gates labeled}. 
In figure \ref{fig:thefig} the gates are ordered from $0$ to $2$, in order from nearest to the inputs to farthest from the inputs.
Alice begins by garbling gate $G_0$, the gate nearest to the inputs\footnote{Multiple gates at some point could equidistant from the input. In these cases, the ordering of gates does not matter.}.

% http://tex.stackexchange.com/questions/55213/how-to-draw-a-boolean-circuit-diagram-in-circuitikz
% http://texdoc.net/texmf-dist/doc/latex/circuitikz/circuitikzmanual.pdf
% adapted from figure on page 40

% Wires
Alice assigns two wire labels to each wire associated with gate $G_0$ - this includes wires $W_0$, $W_1$ and $W_5$.
For each wire, the zeroith label represents $0$ denoted $W_i^0$ and the other label represents $1$ denoted $W_i^1$ for the $i$th wire.
\al{explain what each wi label represents}
A wire labels is a ciphertext, the output of the encryption algorithm\footnote{A common encryption algorithm used now is AES-128, so the wire labels are 128 bit strings.}.
Alice assigns the wire labels by randomly sampling from $\{0,1\}^{\lambda}$, where $\lambda$ is the size of the output of the encryption algorithm.

After assigning labels to $W_0^0$, $W_0^1$, $W_1^0$, $W_1^1$, $W_5^0$ and $W_5^1$, Alice creates a garbled table $T_{G_0}$ for $G_0$.
Gate $G_0$ is an AND gate, and the structure of the table resembles the logical table for an AND gate.
The table has four columns. 
The first two columns are the input wire labels.
The third column is the wire labels for the output wire.
The wire label placed in the third column is based on logical operation of the AND gate.
For example, the third column and third row has the wire label associated with $0$, since AND outputs zero on input of $0$ and $1$.
The fourth column is the dual-key cipher encryption\footnote{See section \al{what section?} for information on dual-key ciphers} of the value in the third column, using the values of the first two columns as keys.
The garbled table for $G_0$ is shown in table \ref{tbl:g0-table}

\begin{table}[h]
\centering
\label{tbl:g0-table}
\begin{tabular}{|c|c|c|c|}
\hline
$W_0$ & $W_1$ & $W_5$ & Encryption \\
\hline
$W_0^0$ & $W_1^0$ & $W_5^0$ & $\Enc_{W_0^0, W_1^0}(W_5^0)$ \\
$W_0^1$ & $W_1^0$ & $W_5^0$ & $\Enc_{W_0^1, W_1^0}(W_5^0)$ \\
$W_0^0$ & $W_1^1$ & $W_5^0$ & $\Enc_{W_0^0, W_1^1}(W_5^0)$ \\
$W_0^1$ & $W_1^1$ & $W_5^1$ & $\Enc_{W_0^1, W_1^1}(W_5^1)$ \\
\hline
\end{tabular}
\caption{A garbled table for an AND gate with input wires $W_0$ and $W_1$ and output wire $W_5$.}
\end{table}

Alice creates wire labels for all remaining wires, and creates garbled tables all remaining gates.
She then sends the fourth column all of garbled tables to Bob.
The fourth column is an encryption of the gate.
Say a gate was input wires $W_i$ and $W_j$ and output wire $W_k$.
Bob can acquire a wire label of $W_k$ (i.e. $W_k^0$ or $W_k^1$) if he has one wire label of $W_i$ (i.e. $W_i^0$ or $W_i^1$) and one wire label of $W_j$ (i.e. $W_j^0$ or $W_j^1$).

Recall that Alice's input to the 2PC protocl are $x = x_0x_1$ where $x_1, x_0 \in \{0,1\}$.
Alice, to send her input to Bob, sends Bob the wire labels $W_0^{x_0}$ and $W_1^{x_1}$.
Bob does not know the values of $x_0$ or $x_1$, because he is simply receiving two ciphertexts, and does not know which value the ciphertexts represent.
The only information that Bob has is the fourth column of the garbled tables, and that does not provide any information about the sematic value of the wire labels.

Recall that Bob's input to the 2PC protocol is $y = y_0 y_1$ where $y_1, y_0 \in \{0,1\}$.
Alice now wants to send Bob $W_2^{y_0}$ and $W_3^{y_1}$, but does not know $y_0$ and $y_1$.
Alice and Bob can achieve this by using Oblivious Transfer, as described in chapter 1.
We focus on wire $W_2$.
Alice has two possible values that she wants to send to Bob: $W_2^0$ and $W_2^1$.
Alice only wants Bob to acquire one of the values, becuase otherwise he can decrypt multiple rows garbled table.
\al{introduce htis OT notation in chapter 1}
Bob wants to receive $W_2^{y_0}$, as that wire label corresponds to his input.
So Alice and Bob do $\OT(\{W_2^0, W_2^1\}, y_0)$, so that Alice obvliously sends Bob the correct wire label.
Alice and Bob also perform OT on wire $W_3$; in particular, they do $\OT(\{W_3^0, W_3^1\}, y_1)$.

Alice is finished garbling the circuit, and communicating information to Bob. 
Bob has everything he needs to ungarble, or decrypt, the circuit.
Bob starts with gate $G_0$, for which he has the fourth column of $T_{G_0}$, a wire label for wire $0$, which I denote $W_0^*$ since Bob does not which wire label it is, and $W_1^*$ accordingly.
Bob starts with the first row of $T_{G_0}$ and tries decrypting the value using $W_0^*$ and $W_1^*$.
Formally, Bob tries $\Dec_{W_0^*, W_1^*}(T_{G_0}\big[0\big])$ where $T_{G_0}\big[0\big]$ represents the value in the zeroith row of $T_{G_0}$.
Bob tries decrypting the values in all four rows of the garbled table $T_{G_0}$, but only one should work, since the other decryptions using the incorrect keys.
For Bob to recognize that encryption is failing, we add an additional property to the encryption scheme: the output of the decryption function should indicate whether the decryption was valid.
A single additional bit, where $0$ represents that decryption failed and $1$ represents that decryption was successful. 
It is noteworth that such a property is common to encrypion schemes, and can be added to any existing encryption if necessary.
With this property, as Bob tries decrtyping all four rows of the garbled table, only one should decrypt correctly.
Because of the way Alice constructed the garbled table, Bob knows that this correclty decrypted value is one of the wire labels of $W_5$, the output wire of gate $G_0$.
Bob then assigns this decrypted value to $W_5^*$, and uses the value as the input wire when decrypting gate $G_2$.

Bob repeats this same process for gate $G_1$ and for gate $G_2$.
For gate $G_2$, Bob uses wire labels $W_5^*$ and $W_6^*$ which he acquired by ungarbling gates $G_0$ and $G_1$.
Bob notifes Alice after acquiring $W_7^*$.
Alice sends him values $W_7^0$ and $W_7^1$.
If $W_7^* = W_7^0$, then the function output $0$ and Bob notifes Alice that the output was $0$.
Otherwise if $W_7^* = W_7^0$, then the function output $1$ and Bob notifes Alice that the output was $1$.

Bob and Alice have now securely computed the function.

\al{Match notation in this description with the algorithms}

\begin{algorithm}
\caption{Garble Circuit}
\label{alg:garble}
\begin{algorithmic}
    \Require Circuit $f(x,\cdot)$ 
    \Ensure Populate garbled tables $f(x,\cdot).tables$.
\For{wire $w_i$ in $f(x,\cdot).wires$} 
    \State Generate two encryption keys, called garbled values, $W_i^0$ and $W_i^1$.
    \State Assign $(W_i^0, W_i^1)$ to $w_i$.
\EndFor \\

\For{gate $g$ in $f(x,\cdot).gates$}
    \State Let $w_i$ be $g$'s first input wire.
    \State Let $w_j$ be $g$'s second input wire.
    \State Let $w_k$ be $g$'s output wire.
    \For{$(u,v) \in \{(0,0), (0,1), (1,0), (1,1)\}$}
    \State $T_g[u,v] = \Enc_{W_i^u}( \Enc_{W_j^v} ( W_k^{g(u,v)}))$
    \al{use DKC}
    \EndFor
    \State $f(x,\cdot).tables[g] = T_g$.
\EndFor
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Evaluate Circuit}
\label{alg:evaluate}
\begin{algorithmic}

\Require $(input\_wires, tables, gates)$
\For{Input wire $w_i$ in $input\_wires$}
	\Comment retrieve garbled values of input wires
	\State Perform OT$(w_i, x_i)$ 
	\Comment retrieve $W^{x_i}_i$ from Alice
	\State Save the value to $w_i$.
\EndFor

\For{Gate $g$ in $gates$}
	\Comment compute the output of each gate.
	\State Let $w_i$ be $g$'s first input wire.
	\State Let $w_j$ be $g$'s second input wire.
	\State Let $w_k$ be $g$'s output wire.
	\State \textbf{Require} $w_i$ and $w_j$ have been assigned garbled values.
	\State \textbf{Require} $w_k$ has not been assigned a garbled value.
    	\For{$(u,v) \in \{(0,0), (0,1), (1,0), (1,1)\}$}
        \al{use DKC}
		\State $temp = \Dec_{w_j}(\Dec_{w_i}(tables[g][u,v]))$
		\If{$temp$ decrypted correctly}
			\State $w_k = temp$
		\EndIf
	\EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

\subsection{Step 0: Setup}
Alice and Bob wish to compute the function $f$, which is represented by a circuit (see section \ref{secn:circuit}).
Alice is the garbler, and will create and encrypt the circuit.
Bob is the evaluator, and will compute the circuit.

\subsection{Step 1: Garbling the Circuit}
\al{define a wire and a label}
Alice garbles each gate, according to algorithm \ref{lag:garble}, resulting in a table $T_g$ for each gate $g$.
The table enables the computation of a single gate $g$, if one is given either $W^0_i$ or $W^1_i$ and either $W^0_j$ or $W^1_j$ where wire $i$ and $j$ are the input wires to $g$.
Figure \ref{example} gives an example of a table for an AND gate.
\al{TODO}

\subsection{Step 2: Bob's Input and Computing the Circuit}
Alice sends the garbled circuit to Bob. 
The garbled circuit consists of a garbled table for each gate, $f(x,\cdot).tables$, and the rules for connecting the gates together.
In order for Bob to compute the circuit, he needs the garbled values of all input wires.
Once he has the garbled values of the input wires, he can decrypt the first few gates, and acquire the decryption keys of the other gates until he has the keys to decrypt all of the gates in the circuit, yielding the output.
Bob can acquire the garbled values of the input wires from Alice using 1-out-of-2 oblivious transfer on each input wire (see section \ref{sctn:oblivious_transfer}).
If necessary, Bob sends the final output of the circuit to Alice. 
This is necessary only if $f_1(x,y) = f_2(x,y)$. 
Bob's protocol is outlined in more detail in Algorithm \ref{alg:evaluate}.

\subsection{Explanation of the security of Yao's protocol}
To do.

\subsection{Notes about complexity}
1 OT per (input?) wire.
4 cts per gate.
How much encryption?
Not good enough for practice.

\section{GMW}
Where Yao's protocol is premised on encrypting gates individually, GMW's protocol for garbling circuits is premised on secret sharing, and performing operations on the shared secrets. 
Secret sharing, in general, is a class of methods for distributing a secret to a group of participants, where each participants is allocated a \textit{share} of the secret. 
The secret can only be reconstructed when a sufficient number of the participants combine their shares, but any pool of insufficient shares yields no information about the secret.

GMW begins by having Alice and Bob secret share their inputs, so each party now has a collection of \textit{shares}. 
Algorithm \ref{alg:gmw_setup} describes this process in more detail.
Then Alice and Bob perform a series of operations on their shares, which are dictated by the gates in the function they wish to compute.
As with Yao's protocol, a gate may either compute XOR, AND or NOT.
Each operation requires a different series of operations, which are described in Algorithm \ref{alg:gmw_gates}.
Finally, Alice and Bob publicize their shares to each other, at which point each party will have sufficient shares to compute the output of the function.

\begin{algorithm}[h!]
\caption{GMW Setup}
\label{alg:gmw_setup}
\begin{algorithmic}
% http://crypto.biu.ac.il/gmw-multi-party-protocol-and-oblivious-transfer-extension
    \State Alice does the following on input Circuit $f(x,\cdot)$ and $x = x_0x_1\ldots x_n$
    \For{wire $w_i$ in $f(x, \cdot).wires$}
        \State Assign $a^1_{w_i} \leftarrow \{0,1\}$
        \Comment a uniform random selection of $0$ or $1$.
        \State Assign $b^1_{w_i} = x_i \oplus a_{w_i}^1$
    \EndFor
    \State Bob does likewise on input Circuit $f(x,\cdot)$ and $y = y_0y_1\ldots y_n$
    \State Hence Alice has generated shares $\{a^1_w, b^1_w\}_w$ 
    \State and Bob has generated shares $\{a^2_w, b^2_w\}_w$
    \State Alice and Bob divide the shares such that Alice has all $a_w$ and Bob has all $b_w$.
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{GMW Gate Evaluation}
\label{alg:gmw_gates}
\begin{algorithmic}
    \State \textbf{XOR Gate}
    \Comment $x_i \oplus y_i = (a_{w_i}^1 \oplus b_{w_i}^1) \oplus (a_{w_i}^2 \oplus a_{w_i}^2)$
    \State Alice evaluates $a_{w_i}^1 \oplus a_{w_i}^2$
    \State Bob evaluates $b_{w_i}^1 \oplus b_{w_i}^2$
    \\
    
    \State \textbf{AND Gate}
    \Comment $x_i \wedge y_i = (a_{w_i}^1 \oplus b_{w_i}^1) \wedge (a_{w_i}^2 \oplus a_{w_i}^2)$
    \State Alice samples $\sigma \leftarrow \{0,1\}$
    \Comment a uniform random selection of $0$ or $1$
    \State Alice constructs table $T$:
     \For{$(u,v) \in \{(0,0), (0,1), (1,0), (1,1)\}$}
     	\State $T[u,v] = (a^1_{w_i} \oplus u) \wedge (a^2_{w_i} \oplus v)$
	\State $s[u,v] = \sigma \oplus T[u,v]$.
     \EndFor    
     \State Do 1-4OT. Alice sends $(s[0,0], s[0,1], s[1,0], s[1,1])$ 
     \State Bob selects result based on $(u,v) = (b^1_{w_i}, b^2_{w_i})$.
    \\
    
    \State \textbf{NOT Gate}
    \Comment $w_i = (\neg a_{w_i}) \oplus (\neg b_{w_i})$
    \State $\triangleright$ Evaluate the negative of a particular wire $w_i$. 
    \State $w_i = a_{w_i} \oplus b_{w_i}$
    \State Let $a'_{w_i} = 1 \oplus a_{w_i}$
    \Comment i.e. $a'_{w_i} = \neg a_{w_i}$
    \State Let $b'_{w_i} = 1 \oplus b_{w_i}$
    \Comment i.e. $b'_{w_i} = \neg b_{w_i}$
\end{algorithmic}
\end{algorithm}

\al{see mike rosulek first few slides for good images. }
\al{illustration about translating bits over to wire labels}
