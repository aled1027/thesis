%!TEX root = thesis.tex
\chapter{Classic 2PC}

Using the tools of Chapter 1, this chapter presents a classic method of performing two-party computation: garbled circuits.
Garbled circuits were first proposed at the first prevention of secure computation in an oral presentation by Andrew Yao \cite{yao86}.
There are other methods of performing secure computation, but this thesis focuses on garbled circuits. 
We begin this chapter by motivating and describing desirable properties of 2PC protocols, culminating in a definition of security. 
We then describe garbled circuits and discuss their security.

\section{2PC Security Motivation}
Think back to Alice and Bob from the introduction. 
Alice and Bob are millionaires who wish to determine who is wealthier without disclosing how much wealth they have.
More formally, Alice has input $x$ and Bob has input $y$ ($x$ and $y$ are integers corresponding to the wealth of each party), and they wish to compute the less than function $f$, such that 
\begin{equation}
f(x,y) = \left\{
\begin{array}{lr}
    1 & \text{if } x < y \text{;} \\
    0 & \text{otherwise.}
\end{array}
\right.
\end{equation} 

We call the overarching interaction between Alice and Bob protocol $\Pi$, and $\Pi$ consists of all messages exchanged and computations performed.
Based on the setup of the problem, we can list a few properties that Alice and Bob wish $\Pi$ to have.
\begin{description}
    \item[Privacy] 
        Parties only learn their output. 
        Any information learned by a single party during the execution of $\Pi$ must be deduced from the output. 
        For example, if Alice learns that she had more money after computing $f$, then she learns that $y < x$; this information about $y$ is deducible from the output therefore it is reasonable.
        It would be unreasonable if Alice learns that $1,000,000 < y < 2,000,000$, as that information is not deducible from $f(x,y)$.
    \item[Correctness] 
        Each party receives the correct output.
        In the case of Alice and Bob, this simply means that they learn correctly who has more money.

\end{description}

One possible method for constructing a definition of security would be to list a number of properties a secure protocol must have.
This approach is unsatisfactory for a number of reasons.

One reason is that is that if we use properties, we may miss certain security properties that are only relevant in certain cases. 
There are many applications of 2PC, and in some cases, an important security property may be lurking in the shadows. 
Ideally, a good definition of 2PC works for all applications, hence capturing all desirable properties.
A second reason that the property based definition is unsatisfactory is that the definition should be simple.
If the definition is simple, then it should be clear that \textit{all} possible attacks against the protocol are prevented by the definition.
With a definition based on properties, it becomes the burden of the prover of security to show that all relevant properties are covered \cite{lindell2009}.

We must also think about the aims of each party involved in the protocol. 
Can we trust that the parties are going to obey the protocol? 
Are the parties going to try to cheat?
These considerations are called the \textit{security setting}.
There are two primary security settings: the semi-honest setting and the malicious setting. 

The work presented in this thesis uses the semi-honest setting. 
In the semi-honest setting, we assume that each party obeys the protocol but tries to learn as much as possible from the information they are given.
This means that parties do not lie about their information, they do not abort, do not send out of order, do not withhold messages or deviate in any way from what is specified in the protocol. 
In contrast, the malicious setting considers that each party is liable to lie and cheat; parties can take any action to learn more information.

The malicious setting is much more realistic. 
Parties that are involved in cryptographic protocols are liable to lie and cheat, for why else would they even be engaged in the cryptographic protocol in the first place?
There are two main reasons why the semi-honest setting is useful.
The first is that many protocols can be constructed for the semi-honest setting, and then improved to function in the malicious setting.
There is a strong history of this occurring with protocols.
It is simply easier to think through and create protocols for the semi-honest setting; at the very least, it is a valuable starting point for building complex crypto-systems.
In the case of 2PC, there exist malicious protocols, and in fact, the primary 2PC protocol that this thesis uses, garbled circuits, can be improved to be malicious secure without too much difficulty. 

The second reason that the semi-honest setting is useful is because it does have real world use cases.
There are some scenarios where parties want to compute a function amongst themselves, and trust each other to act semi-honestly.
One example is hospitals sharing medical data.
Hospitals are legally, and arguably ethically, restricted from sharing medical data, but this data can have great value especially when aggregated with datasets from other hospitals.
2PC offers hospitals the means to ``share'' their data, perform statistics and other operations on it, while keeping the data entirely private. 
Other examples where semi-honesty is sufficient include mutually trusting companies and government agencies.

\section{2PC Security Definition}
% page 620 of Goldreich volume 2
In this section we discuss the definition of 2PC security at a high level, and then give the formal definition. 
The definition of security for 2PC protocols is the most complicated cryptographic theory that we have encountered thus far. 

Recall our setup: Alice and Bob are semi-honest parties with inputs $x$ and $y$ respectively who wish to compute the function $f: \{0,1\}^n \times \{0,1\}^n \to \{0,1\}^m \times \{0,1\}^m$.
The protocol $\Pi$ is a 2PC protocol, that is, $\Pi$ is a series of instructions that Alice and Bob follow which enables them to compute $f$.
To think about the security of $\Pi$, we imagine an ideal world where the protocol is computed securely, and compare the ideal world to the real world where $\Pi$ is executed.

In the ideal world, we imagine that there is a third, trusted and honest party Carlo.
Instead of Alice and Bob communicating amongst each other, Alice and Bob send their inputs to Carlo.
Carlo computes $f(x,y)$ himself and sends the output to Alice and Bob.
The only information that Alice and Bob have in the ideal world is their individual inputs and the output.

Informally, we say that $\Pi$ is secure if Alice and Bob learn \textit{essentially the same} information executing $\Pi$ in the real world as they do computing $f$ in the ideal world with Carlo.
If either Alice or Bob manage to learn more information in the real world, then the protocol $\Pi$ is leaking information that cannot be deduced from their individual inputs and the output of $f$.
This idea of security is formally achieved using the concept of computational indistinguishability presented in Chapter 1. 
Recall that computational indistinguishability is the idea that two probability distributions are essentially the same - no polynomial time algorithm can distinguish them.
To use computational indistinguishability, we think of the information that Alice and Bob learn in the real and ideal world as probability distributions.
The idea may seem fuzzy now, but the idea will become clearer as the probability distributions are explained

To construct the probability distribution of Alice and Bob's information in the ideal world, we introduce \textit{simulators} $S_A$ and $S_B$.
Simulators $S_A$ and $S_B$ are probabilistic polynomial-time algorithms who are essentially adversaries, like the adversary in the definition of encryption from Chapter 1, that specifically attack the ideal world.
Simulator $S_A$ takes as input $x$, Alice's input, and $f(x,y)$, the output of the function because that is the information that Alice has access to in the ideal world.
Likewise, $S_B$ takes input $y$ and $f(x,y)$, since that the is information that Bob has access to in the ideal world.

To create a probability distribution, we consider what $S_A$ does over all possible inputs: the distribution of the possible outputs is given by $\{S_A(x, f(x,y)\}_{x \in \{0,1\}^*}$.
Let us break this distribution down: $S_A$ is a fixed single algorithm, $x$ is Alice's input and $f(x,y)$ is the output of the function.
The set is indexed by all possible $x$, so all possible inputs that Alice could have.
In summary, $\{S_A(x, f(x,y)\}_{x \in \{0,1\}^*}$ represents the possible information that an algorithm could deduced from all possible $x$ and $f(x,y)$.
We think of $\{S_B(y, f(x,y)\}_{y \in \{0,1\}^*}$ for Bob's input similarly.

In the real world, we need to consider what information Alice and Bob have at their disposal.
Recall that Alice and Bob are semi-honest, which means that Alice and Bob follow all instructions of $\Pi$, but they use any information they receive along the way.
More precisely, Alice and Bob obey the protocol, but they also maintain a record of all messages sent and received.
We call Alice's record of communications Alice's \textit{view}, denoted $\viewrv_A(x, y)$, which depends on inputs $x$ and $y$.
We can now create the probability distribution for Alice: $\{\viewrv_A(x, y)\}_{x, y \in \{0,1\}^*}$.
This distribution represents Alice's information from the exchanged messages indexed over all possible inputs $x$ and $y$.
Likewise, we call Bob's record of intermediate computations Bob's view, $\viewrv_B(x, y)$, and his probability distribution of intermediate computations is $\{\viewrv_B(x, y)\}_{x,y \in \{0,1\}^*}$

In summary, if $\Pi$ in the real world is the same as the protocol Alice, Bob and Carlo run in the ideal world, then the simulator $S_A$ and $S_B$ should only be able to learn what can be learned from the intermediate computations. 
That is, the probability distributions $\{S_A(x, f(x,y)\}_{x \in \{0,1\}^*}$ and $\{\viewrv_A(x, y)\}_{x, y \in \{0,1\}^*}\}$ should be essentially the same, i.e., computationally indistinguishable.

With this intuition in mind, we give Goldreich's definition of 2PC security from his textbook \textit{Foundations of Cryptography Volume II}\cite{goldreich}.

\begin{definition}
Let $f = (f_1, f_2)$ be a probabilistic, polynomial time functionality where Alice and Bob compute $f_1, f_2: \{0,1\}^n \to \{0,1\}^m$ respectively.
Let $\Pi$ be a two party protocol for computing $f$. 
Define $\viewrv_i^{\Pi}(n,x,y)$ (for $i \in \{1,2\}$) as the view of the $i$th party on input $(x,y)$ and security parameter $n$.
$\viewrv_i^{\Pi}(n,x,y)$ equals the tuple $(1^n, x, r^i, m_1^i, \ldots, m_t^i)$, where $r^i$ is the contents of the $i$th party's internal random tape, and $m_j^i$ is the $j$th message that the $i$th party received.
Define $output^{\Pi}_i(n,x,y)$ as the output of the $i$th party on input $(x,y)$ and security parameter $n$.
Also denote $ \outputrv^{\Pi}(n,x,y) = (\outputrv^{\Pi}_1(n,x,y), \outputrv^{\Pi}_2(n,x,y)).$
Note that $\viewrv^{\Pi}_i$ and $\outputrv^{\Pi}_i$ are random variables whose probabilities are taken over the random tapes of the two parties. 

We say that $\Pi$ securely computes $f$ in the presence of static semi-honest adversaries if there exist probabilistic polynomial time algorithms $S_1$ and $S_2$ such that for all $x,y \in \{0,1\}^*$, where $|x| = |y|$, the following hold:
\begin{equation} 
    \label{eqn:secdef1}
    \{(S_1(x, f_1(x,y), f(x,y)))\}_{x,y} \compindist \{(\viewrv^{\Pi}_1(x,y), \outputrv^{\Pi}(x,y)) \}_{x,y} 
\end{equation}
\begin{equation} 
    \label{eqn:secdef2}
    \{(S_2(x, f_2(x,y), f(x,y)))\}_{x,y} \compindist \{(\viewrv^{\Pi}_2(x,y), \outputrv^{\Pi}(x,y)) \}_{x,y} 
\end{equation}
\end{definition}

The definition requires that $|x| = |y|$; however, this constraint can be overcome by padding the shorter input.

A definition of 2PC security with malicious parties is substantially more complex.
For more information on a malicious security definition, we refer the reader to \cite{lindell2009}.

\section{Yao's Garbled Circuit}
We now discuss a popular 2PC scheme called garbled circuits.
In garbled circuits, one party, Alice, designs a circuit that computes $f$.
Alice encrypts, or \textit{garbles}, the circuit and sends the encrypted circuit to Bob, along with some values corresponding to her and Bob's inputs.
Bob decrypts the circuit, acquiring the value $f(x,y)$.

\input{figure-gc-highlevel}

\input{figure-labeled-circuit}

We now walk through how Alice garbles a circuit.
She starts with a boolean circuit, like the one shown in figure \ref{fig:labeled-circuit}.
In the figure, the gates are ordered from $0$ to $2$, in order from nearest to the inputs to farthest from the inputs.
Alice begins by assigning two wire labels to each wire - a wire is a line connecting inputs and gates in the figure.
Because Alice is working with a boolean circuit, each wire can semantically represent either a 0 or 1.
For a given wire $W_i$, the zeroith wire label $W_i^0$ represents $0$, and the first wire label $W_i^1$ represents $1$.
A wire labels is a ciphertext, the output of the encryption algorithm.\footnote{A common encryption algorithm used now is AES-128, so the wire labels are 128 bit strings.}
Alice assigns the wire labels by randomly sampling from $\{0,1\}^{\lambda}$, where $\lambda$ is the size of the output of the encryption algorithm.

In general, we use $W_i$ to represent the $i$th wire, $W_i^j$ to represent the $i$th wire's $j$th label, and later we use $W_i^*$ to represent one of wire $i$'s wire labels without specifying whether it is wire label 0 or wire label 1.

After assigning wire labels, Alice garbles gate $G_0$, the gate nearest to the inputs\footnote{Multiple gates at some point could equidistant from the input. In these cases, the ordering of gates does not matter.}.
Alice garbles gate $G_0$ by creating a garbled table $T_{G_0}$.
Gate $G_0$ is an AND gate, so the structure of the table resembles the logical table for an AND gate.
The table has four columns. 
The first two columns are the input wire labels of the input wires $W_0$ and $W_1$.
The third column is the wire labels for the output wire $W_4$

The wire label placed in the third column is based on logical operation of the AND gate.
For example, the first three rows of the third column have the wire label associated with $0$, since AND outputs 0 if any inputs are 0.
The fourth column is the dual-key cipher encryption\footnote{See section Chapter 1 for information on dual-key ciphers} of the value in the third column, using the values of the first two columns as keys.
The garbled table for $G_0$ is shown in table \ref{tbl:g0-table}.

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
$W_0$ & $W_1$ & $W_4$ & Encryption \\
\hline
$W_0^0$ & $W_1^0$ & $W_4^0$ & $\Enc_{W_0^0, W_1^0}(W_4^0)$ \\
$W_0^1$ & $W_1^0$ & $W_4^0$ & $\Enc_{W_0^1, W_1^0}(W_4^0)$ \\
$W_0^0$ & $W_1^1$ & $W_4^0$ & $\Enc_{W_0^0, W_1^1}(W_4^0)$ \\
$W_0^1$ & $W_1^1$ & $W_4^1$ & $\Enc_{W_0^1, W_1^1}(W_4^1)$ \\
\hline
\end{tabular}
\caption[Garbled table of an AND gate]{A garbled table for an AND gate with input wires $W_0$ and $W_1$ and output wire $W_4$.}
\label{tbl:g0-table}
\end{table}

Alice creates garbled tables for each remaining gate; in this case, $G_1$ and $G_2$.
She then sends the fourth column all of garbled tables, the encryption of the respective out-wires, to Bob.
Now if Bob has a label for each input wire, then Bob can acquire one of the labels of the output wire.
Say a gate has input wires $W_i$ and $W_j$ and output wire $W_k$.
Bob can acquire a wire label of $W_k$ (i.e., $W_k^0$ or $W_k^1$) if he has one wire label of $W_i$ (i.e. $W_i^0$ or $W_i^1$) and one wire label of $W_j$ (i.e. $W_j^0$ or $W_j^1$).

Alice cannot send the fourth column of the garbled table to Bob as it is. 
Since the table is ordered, Bob can interpret the semantic value of wire $W_k$ based on which row successfully decrypts. 
The fix is simple: Alice randomly permutes the rows of the table prior to sending.

In order to decrypt each gate, Bob needs to first acquire the wire labels of the input wires, $W_0$, $W_1$, $W_2$ and $W_3$.
Recall that Alice's input to the 2PC protocol are $x = x_0x_1$ where $x_1, x_0 \in \{0,1\}$.
Alice communicates her input to Bob, without revealing values of $x_i$, by sending wire labels $W_0^{x_0}$ and $W_1^{x_1}$.
Bob does not know the values of $x_0$ or $x_1$, because he is simply receiving two ciphertexts, and does not know which value the ciphertexts represent.
The only information that Bob has is the fourth column of the garbled tables, and that does not provide any information about the semantic value of the wire labels.

Recall that Bob's input to the 2PC protocol is $y = y_0 y_1$ where $y_1, y_0 \in \{0,1\}$.
Alice now wants to send Bob $W_2^{y_0}$ and $W_3^{y_1}$, but she does not know and cannot know (for the sake of security) $y_0$ and $y_1$.
Alice and Bob can achieve this by using Oblivious Transfer, as described in Chapter 1.
As an example, we look at wire $W_2$.
Alice potentially sends $W_2^0$ and $W_2^1$ to Bob.
Alice only wants Bob to acquire one of the values, because otherwise he can decrypt multiple rows garbled table.
Bob wants to receive $W_2^{y_0}$, as that wire label corresponds to his input.
In terms of the post office metaphor from Chapter 1, Alice gives $W_2^0$ and $W_2^1$ to the post office, and Bob notifies the post office that he wants message $y_0$.
The post office gives $W_2^{y_0}$ to Bob, but does not tell Bob anything about $W_2^{1 - y_0}$ and does not tell Alice which message Bob requested. 
Alice and Bob also perform OT on wire $W_3$, such that Bob acquires wire label $W_3^{y_1}$.

Alice is finished garbling the circuit, and finished communicating information to Bob. 
Bob has everything he needs to evaluate, or decrypt, the circuit.
Bob starts with gate $G_0$, for which he has the fourth column of $T_{G_0}$, a wire label for wire $W_0$, which I denote $W_0^*$ since Bob does not know which wire label it is, and $W_1^*$ accordingly.
Bob starts with the first row of $T_{G_0}$ and tries decrypting the value using $W_0^*$ and $W_1^*$.
Formally, Bob tries $\EncInv_{W_0^*, W_1^*}(T_{G_0}\big[0\big])$ where $T_{G_0}\big[0\big]$ represents the value in the zeroith row of $T_{G_0}$.
Bob tries decrypting the values in all four rows of the garbled table $T_{G_0}$, but only one should work, since the other decryptions using the incorrect keys.

For Bob to recognize that encryption is failing, we add an additional property to the encryption scheme: the output of the decryption algorithm should indicate whether the decryption was valid.
The decryption algorithm outputs a single additional bit, where 1 indicates that decryption was successful and 0 indicates that decryption failed, i.e., that keys or ciphertext were invalid.
It is noteworthy that such a property is common to encryption schemes, and can be added to any existing encryption if necessary.
With this property, as Bob tries decrypting all four rows of the garbled table, only one should decrypt correctly.
Because of the way that Alice constructed the garbled table, Bob knows that this correctly decrypted value is one of the wire labels of $W_4$, the output wire of gate $G_0$.
Bob then assigns this decrypted value to $W_4^*$, and uses the value as the input wire when decrypting gate $G_2$.

Bob repeats this same process for gate $G_1$ and for gate $G_2$.
For gate $G_2$, Bob uses wire labels $W_5^*$ and $W_6^*$ which he acquires by evaluating gates $G_0$ and $G_1$.
Bob notifies Alice after acquiring $W_6^*$.
Alice sends him values $W_6^0$ and $W_6^1$.
If $W_6^* = W_6^0$, then the function output $0$ and Bob notifies Alice that the output was $0$.
Otherwise if $W_6^* = W_6^1$, then the function outputs $1$ and Bob notifies Alice that the output was $1$.
Alice and Bob have now securely computed the function.

%\begin{algorithm}
%\caption{Garble Circuit}
%\label{alg:garble}
%\begin{algorithmic}
%    \Require Circuit $f(x,\cdot)$ 
%    \Ensure Populate garbled tables $f(x,\cdot).tables$.
%\For{wire $w_i$ in $f(x,\cdot).wires$} 
%    \State Generate two encryption keys, called garbled values, $W_i^0$ and $W_i^1$.
%    \State Assign $(W_i^0, W_i^1)$ to $w_i$.
%\EndFor \\
%
%\For{gate $g$ in $f(x,\cdot).gates$}
%    \State Let $w_i$ be $g$'s first input wire.
%    \State Let $w_j$ be $g$'s second input wire.
%    \State Let $w_k$ be $g$'s output wire.
%    \For{$(u,v) \in \{(0,0), (0,1), (1,0), (1,1)\}$}
%    \State $T_g[u,v] = \Enc_{W_i^u}( \Enc_{W_j^v} ( W_k^{g(u,v)}))$
%    \EndFor
%    \State $f(x,\cdot).tables[g] = T_g$.
%\EndFor
%\end{algorithmic}
%\end{algorithm}
%
%\begin{algorithm}
%\caption{Evaluate Circuit}
%\label{alg:evaluate}
%\begin{algorithmic}
%
%\Require $(input\_wires, tables, gates)$
%\For{Input wire $w_i$ in $input\_wires$}
%	\Comment retrieve garbled values of input wires
%	\State Perform OT$(w_i, x_i)$ 
%	\Comment retrieve $W^{x_i}_i$ from Alice
%	\State Save the value to $w_i$.
%\EndFor
%
%\For{Gate $g$ in $gates$}
%	\Comment compute the output of each gate.
%	\State Let $w_i$ be $g$'s first input wire.
%	\State Let $w_j$ be $g$'s second input wire.
%	\State Let $w_k$ be $g$'s output wire.
%	\State \textbf{Require} $w_i$ and $w_j$ have been assigned garbled values.
%	\State \textbf{Require} $w_k$ has not been assigned a garbled value.
%    	\For{$(u,v) \in \{(0,0), (0,1), (1,0), (1,1)\}$}
%		\State $temp = \Dec_{w_j}(\Dec_{w_i}(tables[g][u,v]))$
%		\If{$temp$ decrypted correctly}
%			\State $w_k = temp$
%		\EndIf
%	\EndFor
%\EndFor
%\end{algorithmic}
%\end{algorithm}

\subsection{Security of Garbled Circuits}
The definition of security of a 2PC protocol $\Pi$ given early in Chapter 2 asked us to compare the execution of $\Pi$ in the real world to a protocol running in an ideal world with a trusted third party.
To think about the security of garbled circuits, we think about the information that Alice and Bob acquire throughout the protocol.

The only information that Alice receives from Bob during the execution of garbled circuits is in the OT stage.
Thereby the security on Alice's side is dependent on OT, which we assume to be secure.
Hence, we can confidently say that Alice does not learn anything that undermines security during an execution of garbled circuits.

The security of Bob is more complicated.
Bob learns two sets of information: input labels  and the fourth column of the garbled table for each gate.
The input labels are acquired in two ways: some are sent naively by Alice and some are acquired via OT.
We can be confident that Bob doesn't learn any extra information in the process of receiving the labels, since we are confident that OT does not reveal information, and other labels are coldly sent by Alice.
Moreover, knowing input labels associated with Alice's input doesn't give Bob any information, since he cannot tell if the label is associated with 0 or 1.

The fourth column of the garbled table by itself does not reveal any information to Bob, as it is simply the encryption of things.
Bob has the keys to decrypt some of the values in the garbled table.
We need to be sure that Bob only has the keys to decrypt the single, intended row of the table.
Bob can only decrypt a row of the table if he has both of the labels used as keys.
For gates on that are connected to input wires, Bob only has a single label for each wire, therefore he must only be able to decrypt a single row.
For subsequent gates, Bob will only ever have a single label for each wire, meaning he can only decrypt a single row.

For Bob to learn extra information, he needs to acquire two wire labels for a single wire.
If he can acquire two labels, then he can decrypt the circuit using that wire label, and make deductions about Alice's input. 
Based on the information that Bob has, there is no way he can access two wire labels for a single wire.
This is the intuition behind the security of garbled circuits.
Of course without a formal proof using computational indistinguishability, we cannot be confident that garbled circuits are secure, as there may be an attack that eludes us.
A formal proof of garbled circuits is long and beyond the scope of this paper. 

\subsection{Notes about complexity}
There are three things to think about when considering the complexity of garbled circuits.
The first is the amount of information that needs to be communicated per gate.
Garbled circuits require 4 ciphertexts, that is $4\lambda$ bits.
On top of this communication is Alice sending her input labels, and the communication required to complete OT for Bob's input labels.
OT, if used naively, is a significant contributor to overall bandwidth.

The second thing to consider is the amount of computation that Alice performs.
Alice performs 4 encryptions with a dual-key cipher for each gate.
The third cost to consider is the amount of computation that Bob performs.
Bob performs 4 decryptions with the dual-key cipher for each gate.

These constraints are all important, but in practice the biggest bottlenecks are the communication per gate and Bob's computation, which are correlated as we will see in Chapter 3.
A circuit that computes AES requires approximately 35,000 gates.
If 4 ciphertexts per gate need to communicated, and AES-128 is the encryption scheme, then $4 * 128 * 35,000$ bits = $2.24$ megabytes: a huge amount of communication for just encryption!

%\section{GMW}
%Where Yao's protocol is premised on encrypting gates individually, GMW's protocol for garbling circuits is premised on secret sharing and performing operations on the shared secrets. 
%In general, secret sharing is a class of methods for distributing a secret to a group of participants, where each participants is allocated a \textit{share} of the secret. 
%The secret can only be reconstructed when a sufficient number of the participants combine their shares, but any pool of insufficient shares yields no information about the secret.
%
%GMW begins by having Alice and Bob secret share their inputs, so each party now has a collection of \textit{shares}. 
%Algorithm \ref{alg:gmw_setup} describes this process in more detail.
%Then Alice and Bob perform a series of operations on their shares, which are dictated by the gates in the function they wish to compute.
%As with Yao's protocol, a gate may either compute XOR, AND or NOT.
%Each operation requires a different series of operations, which are described in Algorithm \ref{alg:gmw_gates}.
%Finally, Alice and Bob publicize their shares to each other, at which point each party will have sufficient shares to compute the output of the function.

%\begin{algorithm}[h!]
%\caption{GMW Setup}
%\label{alg:gmw_setup}
%\begin{algorithmic}
%% http://crypto.biu.ac.il/gmw-multi-party-protocol-and-oblivious-transfer-extension
%    \State Alice does the following on input Circuit $f(x,\cdot)$ and $x = x_0x_1\ldots x_n$
%    \For{wire $w_i$ in $f(x, \cdot).wires$}
%        \State Assign $a^1_{w_i} \leftarrow \{0,1\}$
%        \Comment a uniform random selection of $0$ or $1$.
%        \State Assign $b^1_{w_i} = x_i \oplus a_{w_i}^1$
%    \EndFor
%    \State Bob does likewise on input Circuit $f(x,\cdot)$ and $y = y_0y_1\ldots y_n$
%    \State Hence Alice has generated shares $\{a^1_w, b^1_w\}_w$ 
%    \State and Bob has generated shares $\{a^2_w, b^2_w\}_w$
%    \State Alice and Bob divide the shares such that Alice has all $a_w$ and Bob has all $b_w$.
%\end{algorithmic}
%\end{algorithm}
%
%\begin{algorithm}
%\caption{GMW Gate Evaluation}
%\label{alg:gmw_gates}
%\begin{algorithmic}
%    \State \textbf{XOR Gate}
%    \Comment $x_i \oplus y_i = (a_{w_i}^1 \oplus b_{w_i}^1) \oplus (a_{w_i}^2 \oplus a_{w_i}^2)$
%    \State Alice evaluates $a_{w_i}^1 \oplus a_{w_i}^2$
%    \State Bob evaluates $b_{w_i}^1 \oplus b_{w_i}^2$
%    \\
%    
%    \State \textbf{AND Gate}
%    \Comment $x_i \wedge y_i = (a_{w_i}^1 \oplus b_{w_i}^1) \wedge (a_{w_i}^2 \oplus a_{w_i}^2)$
%    \State Alice samples $\sigma \leftarrow \{0,1\}$
%    \Comment a uniform random selection of $0$ or $1$
%    \State Alice constructs table $T$:
%     \For{$(u,v) \in \{(0,0), (0,1), (1,0), (1,1)\}$}
%     	\State $T[u,v] = (a^1_{w_i} \oplus u) \wedge (a^2_{w_i} \oplus v)$
%	\State $s[u,v] = \sigma \oplus T[u,v]$.
%     \EndFor    
%     \State Do 1-4OT. Alice sends $(s[0,0], s[0,1], s[1,0], s[1,1])$ 
%     \State Bob selects result based on $(u,v) = (b^1_{w_i}, b^2_{w_i})$.
%    \\
%    
%    \State \textbf{NOT Gate}
%    \Comment $w_i = (\neg a_{w_i}) \oplus (\neg b_{w_i})$
%    \State $\triangleright$ Evaluate the negative of a particular wire $w_i$. 
%    \State $w_i = a_{w_i} \oplus b_{w_i}$
%    \State Let $a'_{w_i} = 1 \oplus a_{w_i}$
%    \Comment i.e. $a'_{w_i} = \neg a_{w_i}$
%    \State Let $b'_{w_i} = 1 \oplus b_{w_i}$
%    \Comment i.e. $b'_{w_i} = \neg b_{w_i}$
%\end{algorithmic}
%\end{algorithm}
%
