
\chapter{Classic 2PC}
\al{this paragraph is a little weak}
Secure Function Evaluation was first proposed in an oral presesntation by Andrew Yao \cite{yao-original}.
Since Yao's presentation, multiple methods for performing SFE were developed.
One method was developed by Yao himself and is Yao's garbled circuits.
Another was developed by a group of researchers, Beaver, Micali and Widgerson.
The two methods are premised on a similar idea: encrypt a circuit by encrypting its gates, which has since been termed garbled circuit.
At this point, it is unclear which method is better, so researchers continue to study both methods.
\al{get source}

This chapter explains the two most prominent methods of SFE for the two party case, referred to as Two-Party Protocol (2PC).
The first part of the chapter will motivate and describe desirable properties of a 2PC protocol, culminating in a definition. 
The second part of the chapter will describe in Yao's Garbled Circuits, a method for performing 2PC, and give a proof of security. 
The third part will provide an overview of GMW's method.

\section{2PC Security Motivation}
Think back to Alice and Bob from the introduction. 
Alice and Bob are millionaires who wish to determine who is wealthier without disclosing how much wealth they have.
Formally, we say that Alice has input $x$ and Bob has input $y$ ($x$ and $y$ are integers corresponding to the wealth of each party), and they want to compute the less than function $f$, such that 
\begin{equation}
f(x,y) = \left\{
\begin{array}{lr}
    1 & \text{if } x < y \text{;} \\
    0 & \text{otherwise.}
\end{array}
\right.
\end{equation} 

We call the overarching interaction between Alice and Bob protocol $\Pi$, and $\Pi$ consists of all messages exchanged and computations performed.
Based on the setup of the problem, we can list a few properties that Alice and Bob wish $\Pi$ to have.
\begin{description}
    \item[Privacy] 
        Parties only learn their output. 
        Any information learned by a single party during the execution of $\Pi$ must be deduced from the output. 
        For example, in the case of Alice and Bob, if Alice learns that they had more money, then they learn that $y < x$, which is some information about $y$, but it is deduced from the output so it is reasonable. 
        It would be unreasonable if during the execution of $\Pi$ Alice learns that $1,000,000 < y < 2,000,000$, as that information is not deducable from $f(x,y)$.
    \item[Correctness] 
        Each party receives the correct output.
        In the case of Alice and Bob, this simply means that they learn correctly who has more money.
    \item[Fairness] 
        Each party receives their input if and only if the other party receives their input.
        In the case of Alice and Bob, this means that Alice receives their input if and only if Bob receives their input.
        This property prevents the case where Alice sends her input to Bob, Bob computes $f$ with Alice's input and their own input, and then Bob refuses to send their input to Alice. 
        Hence Bob has learned to output of $f$, but Alice hasn't. 
        We do not want to this scenario to happen, so we require that each party receive their input if and only if the party does. 
        We do not require that all parties always receive their inputs, because a party could abort from the execution in the middle of the protocol.
        \footnote{Technically this is incorrect since we assume that each party is semihonest, but the property generalizes more easily when this requirement when considering aborts.}
    \item[Semi-honesty]
        Each party must obey the protocol.
        We are assuming that Alice and Bob are semi-honest agents, which means that Alice and Bob are not malicious, trying to steal information from each other. 
        They are simply trying to compute $f$, but would use the information that they receive in order to deduce information about the other party.
        In contrast, we could imagine the scenario where Alice and Bob are untrustworthy: they would send lies, send the wrong input, or deviate in any number of ways to get the upper hand in the protocol.
        While assuming semi-honesty is not the most realistic scenario, most cryptographic protocols secure with semi-honest agents can be transformed into stronger protocols protecting against malicious agents.
        Morever, the semi-honest protocols are more intuitive.
\end{description}
One possible method for constructing a definition of security would be to list a number of properties a secure protocol must have.
This approach is unsatisfactory for a number of reasons.

One reason is that an import security property that is only releveant in certain cases may be missed.
There are many applications of 2PC, and in some cases, there may be certain properties that critical to security.
Ideally, a good definition of 2PC works for all applications, hence capturing all desirable properties.
A second reason that the property based definition is unsatisfactory is that the definition should be simple.
If the definition is simple, then it should be clear that \textit{all} possible attacks against the protocol are prevented by the definition.
A definition based on properties in this respect as it becomes the burden of the prover of security to show that all relevevant properties are covered \cite{lindell2009secure}.

\section{2PC Security Definition}
A number of definitions formalize what it means for a 2PC protocol to be secure.
Yao, in his 1982 paper on secure function evaluation, says a 2PC protocol is secure if:

\begin{blockquote}
If one participant behaves according the the protocol, the probability that the other participant successfully cheats is at most $\gamma$ for $\gamma \in \{0,1\}$.
\cite{get-source}
\end{blockquote}

TODO mention that this doesn't use the properties.

Since Yao's original definition, many other definitions of security of 2PC protocols have been proposed.
Here we give Goldreich's definition, which is given in his textbook \textit{Foundations of Cryptography Volume II}, and is reproduced in various papers, most notably Lindell and Pinkas 2009 survey paper on SFE \cite{goldreich, lindell2009secure}.

\begin{description}
\item [Setup:] \hfill
    \begin{itemize}
        \item Let $f = (f_1, f_2)$ be a probabilistic, polynomial time functionality where Alice and Bob compute $f_1, f_2: \{0,1\}^n \to \{0,1\}^m$ respectively.

        \item Let $\Pi$ be a two party protocol for computing $f$. 

        \item Define $\viewrv_i^{\Pi}(n,x,y)$ (for $i \in \{1,2\}$) as the view of the $i$th party on input $(x,y)$ and security parameter $n$.
        $\viewrv_i^{\Pi}(n,x,y)$ equals the tuple $(1^n, x, r^i, m_1^i, \ldots, m_t^i)$, where $r^i$ is the contents of the $i$th party's internal random tape, and $m_j^i$ is the $j$th message that the $i$th party received.
    
        \item Define $output^{\Pi}_i(n,x,y)$ as the output of the $i$th party on input $(x,y)$ and security parameter $n$.
        Also denote
        $$ \outputrv^{\Pi}(n,x,y) = (\outputrv^{\Pi}_1(n,x,y), \outputrv^{\Pi}_2(n,x,y)).$$

    \item Note that $\viewrv^{\Pi}_i$ and $\outputrv^{\Pi}_i$ are random variables whose probabilities are taken over the random tapes of the two parties. Also note that for two party computation.
\end{itemize}
\item [Definition:]
    We say that $\Pi$ securely computes $f$ in the presence of static\footnote{\al{TODO} Mention what static means} semi-honest adversaries if there exists probabilistic polynomial time algorithms $S_1$ and $S_2$ such that for all $x,y \in \{0,1\}^*$, where $|x| = |y|$, the following are true:
\begin{equation} 
    \label{eqn:secdef1}
    \{(S_1(x, f_1(x,y), f(x,y)))\}_{x,y} \equiv^C \{(\viewrv^{\Pi}_1(x,y), \outputrv^{\Pi}(x,y)) \}_{x,y} 
\end{equation}
\begin{equation} 
    \label{eqn:secdef2}
    \{(S_2(x, f_2(x,y), f(x,y)))\}_{x,y} \equiv^C \{(\viewrv^{\Pi}_2(x,y), \outputrv^{\Pi}(x,y)) \}_{x,y} 
\end{equation}

\item[Intuition:]
We think of $\viewrv^{\Pi}_i$ as all of the information that the $i$th party has to operate with, such that any conclusion that the $i$th party can come to could be determined from $view^{\Pi}_i$.
Moreover, $\outputrv^{\Pi}_i$ is simply the output of the $i$th party. 
The value of $\outputrv^{\Pi}_i$ is computable from the tuple $\viewrv^{\Pi}_i$.

Equations \ref{eqn:secdef1} and \ref{eqn:secdef2} state that a probabilistic, polynomial time algorithm, denoted $S_1$ and $S_2$, which is given access \textit{only} to the party's input and output can compute the view of a party.
The definition requires that $S_1$ on input $(x, f(x,y))$ must be able to compute $\viewrv^{\Pi}_i(x,y)$, in particular the messages received by party 1, such that the generated view is indistinguishable from the actual view.
If there exists an algorithm that can perform the aforementioned task, then $\Pi$ does not adequately conceal information, so we should not consider $\Pi$ to be secure.

Finally, the definition requires that $|x| = |y|$; however, this constraint can be overcome in practice by padding the shorter input.
\end{description}

The definition of security provided here only applies when adversaries are semi-honest (see \ref{semihonest section}).
Definitions of security in settings with malicious adversaries require substantially more complexity.
As a result, these definitions are often simulation based definitions.
They imagine an ideal world, where the function $f$ must be computed securely, and by a series of comparisons, show that the real world where $\Pi$ computes $f$ is essentially the same as the ideal world.
For an easy to understand security definition of 2PC with malicious adversaries, we refer to reader to \cite{lindell2009}.

\section{Yao's Garbled Circuit}
\al{struggling a bit with the organization of this section}
We now give an implementation of a generic 2PC scheme created by Yao \cite{yao}.
The scheme is designed for two parties, Alice and Bob, who have inputs $x$ and $y$ respectively.
We suppose that Alice and Bob wish to compute the function $f : \{0,1\}^n \to \{0,1\}^m$. 

\al{This should probably be 2-4 sentences, instead of one}
At a high level, Yao's scheme has the following steps: (1) Alice builds and encrypts the circuit representing $f$. (2) Alice sends the garbled (encrypted) circuit to Bob. (3) Bob receives the input labels via Oblivious Transfer. (4) Bob uses the input labels to decrypt the circuit. (5) Bob sends the output of the circuit to Alice.

\begin{algorithm}
\caption{Garble Circuit}
\label{alg:garble}
\begin{algorithmic}
    \Require Circuit $f(x,\cdot)$ 
    \Ensure Populate garbled tables $f(x,\cdot).tables$.
\For{wire $w_i$ in $f(x,\cdot).wires$} 
    \State Generate two encryption keys, called garbled values, $W_i^0$ and $W_i^1$.
    \State Assign $(W_i^0, W_i^1)$ to $w_i$.
\EndFor \\

\For{gate $g$ in $f(x,\cdot).gates$}
    \State Let $w_i$ be $g$'s first input wire.
    \State Let $w_j$ be $g$'s second input wire.
    \State Let $w_k$ be $g$'s output wire.
    \For{$(u,v) \in \{(0,0), (0,1), (1,0), (1,1)\}$}
    \State $T_g[u,v] = \Enc_{W_i^u}( \Enc_{W_j^v} ( W_k^{g(u,v)}))$
    \al{use DKC}
    \EndFor
    \State $f(x,\cdot).tables[g] = T_g$.
\EndFor
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Evaluate Circuit}
\label{alg:evaluate}
\begin{algorithmic}

\Require $(input\_wires, tables, gates)$
\For{Input wire $w_i$ in $input\_wires$}
	\Comment retrieve garbled values of input wires
	\State Perform OT$(w_i, x_i)$ 
	\Comment retrieve $W^{x_i}_i$ from Alice
	\State Save the value to $w_i$.
\EndFor

\For{Gate $g$ in $gates$}
	\Comment compute the output of each gate.
	\State Let $w_i$ be $g$'s first input wire.
	\State Let $w_j$ be $g$'s second input wire.
	\State Let $w_k$ be $g$'s output wire.
	\State \textbf{Require} $w_i$ and $w_j$ have been assigned garbled values.
	\State \textbf{Require} $w_k$ has not been assigned a garbled value.
    	\For{$(u,v) \in \{(0,0), (0,1), (1,0), (1,1)\}$}
        \al{use DKC}
		\State $temp = \Dec_{w_j}(\Dec_{w_i}(tables[g][u,v]))$
		\If{$temp$ decrypted correctly}
			\State $w_k = temp$
		\EndIf
	\EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

\subsection{Step 0: Setup}
Alice and Bob wish to compute the function $f$, which is represented by a circuit (see section \ref{secn:circuit}).
Alice is the garbler, and will create and encrypt the circuit.
Bob is the evaluator, and will compute the circuit.

\subsection{Step 1: Garbling the Circuit}
\al{define a wire and a label}
Alice garbles each gate, according to algorithm \ref{lag:garble}, resulting in a table $T_g$ for each gate $g$.
The table enables the computation of a single gate $g$, if one is given either $W^0_i$ or $W^1_i$ and either $W^0_j$ or $W^1_j$ where wire $i$ and $j$ are the input wires to $g$.
Figure \ref{example} gives an example of a table for an AND gate.
\al{TODO}

\subsection{Step 2: Bob's Input and Computing the Circuit}
Alice sends the garbled circuit to Bob. 
The garbled circuit consists of a garbled table for each gate, $f(x,\cdot).tables$, and the rules for connecting the gates together.
In order for Bob to compute the circuit, he needs the garbled values of all input wires.
Once he has the garbled values of the input wires, he can decrypt the first few gates, and acquire the decryption keys of the other gates until he has the keys to decrypt all of the gates in the circuit, yielding the output.
Bob can acquire the garbled values of the input wires from Alice using 1-out-of-2 oblivious transfer on each input wire (see section \ref{sctn:oblivious_transfer}).
If necessary, Bob sends the final output of the circuit to Alice. 
This is necessary only if $f_1(x,y) = f_2(x,y)$. 
Bob's protocol is outlined in more detail in Algorithm \ref{alg:evaluate}.

\subsection{Explanation of the security of Yao's protocol}
To do.

\subsection{Notes about complexity}
1 OT per (input?) wire.
4 cts per gate.
How much encryption?
Not good enough for practice.

\section{GMW}
Where Yao's protocol is premised on encrypting gates individually, GMW's protocol for garbling circuits is premised on secret sharing, and performing operations on the shared secrets. 
Secret sharing, in general, is a class of methods for distributing a secret to a group of participants, where each participants is allocated a \textit{share} of the secret. 
The secret can only be reconstructed when a sufficient number of the participants combine their shares, but any pool of insufficient shares yields no information about the secret.

GMW begins by having Alice and Bob secret share their inputs, so each party now has a collection of \textit{shares}. 
Algorithm \ref{alg:gmw_setup} describes this process in more detail.
Then Alice and Bob perform a series of operations on their shares, which are dictated by the gates in the function they wish to compute.
As with Yao's protocol, a gate may either compute XOR, AND or NOT.
Each operation requires a different series of operations, which are described in Algorithm \ref{alg:gmw_gates}.
Finally, Alice and Bob publicize their shares to each other, at which point each party will have sufficient shares to compute the output of the function.

\begin{algorithm}[h!]
\caption{GMW Setup}
\label{alg:gmw_setup}
\begin{algorithmic}
% http://crypto.biu.ac.il/gmw-multi-party-protocol-and-oblivious-transfer-extension
    \State Alice does the following on input Circuit $f(x,\cdot)$ and $x = x_0x_1\ldots x_n$
    \For{wire $w_i$ in $f(x, \cdot).wires$}
        \State Assign $a^1_{w_i} \leftarrow \{0,1\}$
        \Comment a uniform random selection of $0$ or $1$.
        \State Assign $b^1_{w_i} = x_i \oplus a_{w_i}^1$
    \EndFor
    \State Bob does likewise on input Circuit $f(x,\cdot)$ and $y = y_0y_1\ldots y_n$
    \State Hence Alice has generated shares $\{a^1_w, b^1_w\}_w$ 
    \State and Bob has generated shares $\{a^2_w, b^2_w\}_w$
    \State Alice and Bob divide the shares such that Alice has all $a_w$ and Bob has all $b_w$.
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{GMW Gate Evaluation}
\label{alg:gmw_gates}
\begin{algorithmic}
    \State \textbf{XOR Gate}
    \Comment $x_i \oplus y_i = (a_{w_i}^1 \oplus b_{w_i}^1) \oplus (a_{w_i}^2 \oplus a_{w_i}^2)$
    \State Alice evaluates $a_{w_i}^1 \oplus a_{w_i}^2$
    \State Bob evaluates $b_{w_i}^1 \oplus b_{w_i}^2$
    \\
    
    \State \textbf{AND Gate}
    \Comment $x_i \wedge y_i = (a_{w_i}^1 \oplus b_{w_i}^1) \wedge (a_{w_i}^2 \oplus a_{w_i}^2)$
    \State Alice samples $\sigma \leftarrow \{0,1\}$
    \Comment a uniform random selection of $0$ or $1$
    \State Alice constructs table $T$:
     \For{$(u,v) \in \{(0,0), (0,1), (1,0), (1,1)\}$}
     	\State $T[u,v] = (a^1_{w_i} \oplus u) \wedge (a^2_{w_i} \oplus v)$
	\State $s[u,v] = \sigma \oplus T[u,v]$.
     \EndFor    
     \State Do 1-4OT. Alice sends $(s[0,0], s[0,1], s[1,0], s[1,1])$ 
     \State Bob selects result based on $(u,v) = (b^1_{w_i}, b^2_{w_i})$.
    \\
    
    \State \textbf{NOT Gate}
    \Comment $w_i = (\neg a_{w_i}) \oplus (\neg b_{w_i})$
    \State $\triangleright$ Evaluate the negative of a particular wire $w_i$. 
    \State $w_i = a_{w_i} \oplus b_{w_i}$
    \State Let $a'_{w_i} = 1 \oplus a_{w_i}$
    \Comment i.e. $a'_{w_i} = \neg a_{w_i}$
    \State Let $b'_{w_i} = 1 \oplus b_{w_i}$
    \Comment i.e. $b'_{w_i} = \neg b_{w_i}$
\end{algorithmic}
\end{algorithm}

\al{see mike rosulek first few slides for good images. }
\al{illustration about translating bits over to wire labels}
